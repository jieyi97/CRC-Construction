{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5946653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary functions\n",
    "def parseTable(fn, sep, header = False,excel = False):\n",
    "    '''takes in a table where columns are separated by a given symbol and outputs\n",
    "    a nested list such that list[row][col]\n",
    "    example call:\n",
    "    table = parseTable('file.txt','\\t')\n",
    "    '''\n",
    "    fh = open(fn)\n",
    "    lines = fh.readlines()\n",
    "    fh.close()\n",
    "    if excel:\n",
    "        lines = lines[0].split('\\r')\n",
    "    if lines[0].count('\\r') > 0:\n",
    "        lines = lines[0].split('\\r')\n",
    "    table = []\n",
    "    if header == True:\n",
    "        lines =lines[1:]\n",
    "    for i in lines:\n",
    "        table.append(i[:-1].split(sep))\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def unParseTable(table, output, sep):\n",
    "    '''takes in a table generated by parseTable and writes it to an output file\n",
    "    takes as parameters (table, output, sep), where sep is how the file is delimited\n",
    "    example call unParseTable(table, 'table.txt', '\\t') for a tab del file\n",
    "    '''\n",
    "    fh_out = open(output,'w')\n",
    "    if len(sep) == 0:\n",
    "        for i in table:\n",
    "            fh_out.write(str(i))\n",
    "            fh_out.write('\\n')\n",
    "    else:\n",
    "        for line in table:\n",
    "            line = [str(x) for x in line]\n",
    "            line = sep.join(line)\n",
    "\n",
    "            fh_out.write(line)\n",
    "            fh_out.write('\\n')\n",
    "            \n",
    "    print(f'write table to {output}')\n",
    "\n",
    "    fh_out.close()\n",
    "    \n",
    "\n",
    "'''uniquify function by Peter Bengtsson Used under a creative commons license\n",
    "sourced from  here: http://www.peterbe.com/plog/uniqifiers-benchmark\n",
    "'''\n",
    "def uniquify(seq, idfun=None):\n",
    "    if idfun is None:\n",
    "        def idfun(x): return x\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen: continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def makeSearchLocus(locus,upSearch,downSearch):\n",
    "    '''takes a locus and expands it by a fixed upstream/downstream amount. spits out the new larger locus\n",
    "    '''\n",
    "    if locus.sense() == '-':\n",
    "        searchLocus = Locus(locus.chr(),locus.start()-downSearch,locus.end()+upSearch,locus.sense(),locus.ID())\n",
    "    else:\n",
    "        searchLocus = Locus(locus.chr(),locus.start()-upSearch,locus.end()+downSearch,locus.sense(),locus.ID())\n",
    "    return searchLocus\n",
    "\n",
    "\n",
    "def importRefseq(refseqFile, returnMultiples = False):\n",
    "\n",
    "    '''\n",
    "    opens up a refseq file downloaded by UCSC\n",
    "    '''\n",
    "    refseqTable = parseTable(refseqFile,'\\t')\n",
    "    refseqDict = {}\n",
    "    ticker = 1\n",
    "    for line in refseqTable[1:]:\n",
    "        if refseqDict.__contains__(line[1]):\n",
    "            refseqDict[line[1]].append(ticker)\n",
    "        else:\n",
    "            refseqDict[line[1]] = [ticker]\n",
    "        ticker = ticker + 1\n",
    "\n",
    "    multiples = []\n",
    "    for i in refseqDict:\n",
    "        if len(refseqDict[i]) > 1:\n",
    "            multiples.append(i)\n",
    "\n",
    "    if returnMultiples == True:\n",
    "        return refseqTable,refseqDict,multiples\n",
    "    else:\n",
    "        return refseqTable,refseqDict\n",
    "\n",
    "    \n",
    "def getTSSs(geneList,refseqTable,refseqDict):\n",
    "    if len(geneList) == 0:\n",
    "        refseq = refseqTable\n",
    "    else:\n",
    "        refseq = refseqFromKey(geneList,refseqDict,refseqTable)\n",
    "    TSS = []\n",
    "    for line in refseq:\n",
    "        if line[3] == '+':\n",
    "            TSS.append(line[4])\n",
    "        if line[3] == '-':\n",
    "            TSS.append(line[5])\n",
    "    TSS = map(int,TSS)\n",
    "    return TSS\n",
    "\n",
    "\n",
    "def refseqFromKey(refseqKeyList,refseqDict,refseqTable):\n",
    "    typeRefseq = []\n",
    "    for name in refseqKeyList:\n",
    "        if refseqDict.__contains__(name):\n",
    "            typeRefseq.append(refseqTable[refseqDict[name][0]])\n",
    "    return typeRefseq\n",
    "\n",
    "\n",
    "def makeStartDict(annotFile,geneList = []):\n",
    "    '''makes a dictionary keyed by refseq ID that contains information about \n",
    "    chrom/start/stop/strand/common name\n",
    "    '''\n",
    "\n",
    "    if type(geneList) == str:\n",
    "        geneList = parseTable(geneList,'\\t')\n",
    "        geneList = [line[0] for line in geneList]\n",
    "            \n",
    "    if annotFile.upper().count('REFSEQ') == 1:\n",
    "        refseqTable,refseqDict = importRefseq(annotFile)\n",
    "        if len(geneList) == 0:\n",
    "            geneList = refseqDict.keys()\n",
    "        startDict = {}\n",
    "        for gene in geneList:\n",
    "            if refseqDict.__contains__(gene) == False:\n",
    "                continue\n",
    "            startDict[gene]={}\n",
    "            startDict[gene]['sense'] = refseqTable[refseqDict[gene][0]][3]\n",
    "            startDict[gene]['chr'] = refseqTable[refseqDict[gene][0]][2]\n",
    "            startDict[gene]['start'] = [*getTSSs([gene],refseqTable,refseqDict)]\n",
    "            if startDict[gene]['sense'] == '+':\n",
    "                startDict[gene]['end'] =[int(refseqTable[refseqDict[gene][0]][5])]\n",
    "            else:\n",
    "                startDict[gene]['end'] = [int(refseqTable[refseqDict[gene][0]][4])]\n",
    "            startDict[gene]['name'] = refseqTable[refseqDict[gene][0]][12]\n",
    "    return startDict\n",
    "\n",
    "\n",
    "def makeTSSLocus(gene,startDict,upstream,downstream):\n",
    "    '''given a startDict, make a locus for any gene's TSS w/ upstream and downstream windows\n",
    "    '''\n",
    "    \n",
    "    start = startDict[gene]['start'][0]\n",
    "    if startDict[gene]['sense'] =='-':\n",
    "        return Locus(startDict[gene]['chr'],start-downstream,start+upstream,'-',gene)\n",
    "    else:\n",
    "        return Locus(startDict[gene]['chr'],start-upstream,start+downstream,'+',gene)\n",
    "    \n",
    "    \n",
    "def fetchSeq(directory,chrom,start,end,UCSC=False,lineBreaks=True,header = True):\n",
    "    '''function that fetches a sequence from a genome directory\n",
    "    directory that contains individual chrom fasta files\n",
    "    '''\n",
    "    fn = directory + chrom + '.fa'\n",
    "    fh = open(fn,'r')\n",
    "    headerOffset = 0\n",
    "    nStart = 0\n",
    "    nEnd = 0\n",
    "    if header:\n",
    "        fh.seek(0)\n",
    "        headerOffset = len(fh.readline())\n",
    "    if lineBreaks:\n",
    "\n",
    "        nStart = int((start-1)/50)\n",
    "        nEnd = int((end-1)/50)\n",
    "    if UCSC:\n",
    "        fh.seek((start+nStart+headerOffset))\n",
    "    else:\n",
    "        fh.seek((start-1+nStart+headerOffset))\n",
    "    span = ((end+nEnd-1)-(start+nStart-1))\n",
    "\n",
    "    read = fh.read(span)\n",
    "    if lineBreaks:\n",
    "        read = read.replace('\\n','')\n",
    "\n",
    "    return read\n",
    "    fh.close()\n",
    "\n",
    "    \n",
    "class Locus:\n",
    "    __chrDict = dict()\n",
    "    __senseDict = {'+':'+', '-':'-', '.':'.'}\n",
    "    def __init__(self,chr,start,end,sense,ID='',score=0):\n",
    "        coords = [int(start),int(end)]\n",
    "        # coords = [start, end]\n",
    "        coords.sort(reverse=False)\n",
    "        if not(self.__chrDict.__contains__(chr)): self.__chrDict[chr] = chr\n",
    "        self._chr = self.__chrDict[chr]\n",
    "        self._sense = self.__senseDict[sense]\n",
    "        self._start = int(coords[0])\n",
    "        self._end = int(coords[1])\n",
    "        self._ID = ID\n",
    "        self._score = score\n",
    "    def ID(self): return self._ID\n",
    "    def chr(self): return self._chr\n",
    "    def start(self): return self._start\n",
    "    def end(self): return self._end\n",
    "    def len(self): return self._end - self._start + 1\n",
    "    def score(self): return self._score\n",
    "    def getAntisenseLocus(self):\n",
    "        if self._sense=='.': return self\n",
    "        else:\n",
    "            switch = {'+':'-', '-':'+'}\n",
    "            return Locus(self._chr,self._start,self._end,switch[self._sense])\n",
    "    def coords(self): return [self._start,self._end]\n",
    "    def sense(self): return self._sense\n",
    "    def overlaps(self,otherLocus):\n",
    "        if self.chr()!=otherLocus.chr(): return False\n",
    "        elif not(self._sense=='.' or \\\n",
    "                 otherLocus.sense()=='.' or \\\n",
    "                 self.sense()==otherLocus.sense()): return False\n",
    "        elif self.start() > otherLocus.end() or otherLocus.start() > self.end(): return False\n",
    "        else: return True\n",
    "    def contains(self,otherLocus):\n",
    "        if self.chr()!=otherLocus.chr(): return False\n",
    "        elif not(self._sense=='.' or \\\n",
    "                 otherLocus.sense()=='.' or \\\n",
    "                 self.sense()==otherLocus.sense()): return False\n",
    "        elif self.start() > otherLocus.start() or otherLocus.end() > self.end(): return False\n",
    "        else: return True\n",
    "    def overlapsAntisense(self,otherLocus):\n",
    "        return self.getAntisenseLocus().overlaps(otherLocus)\n",
    "    def containsAntisense(self,otherLocus):\n",
    "        return self.getAntisenseLocus().contains(otherLocus)\n",
    "    def __hash__(self): return self._start + self._end\n",
    "    def __eq__(self,other):\n",
    "        if self.__class__ != other.__class__: return False\n",
    "        if self.chr()!=other.chr(): return False\n",
    "        if self.start()!=other.start(): return False\n",
    "        if self.end()!=other.end(): return False\n",
    "        if self.sense()!=other.sense(): return False\n",
    "        return True\n",
    "    def __ne__(self,other): return not(self.__eq__(other))\n",
    "    def __str__(self): return self.chr()+'('+self.sense()+'):'+'-'.join(map(str,self.coords()))\n",
    "    def plotStr(self): return self.chr() + ':' + self.sense() + ':' + '-'.join(map(str,self.coords()))\n",
    "    def checkRep(self):\n",
    "        pass\n",
    "    def gffLine(self): return [self.chr(),self.ID(),'',self.start(),self.end(),'',self.sense(),'',self.ID()]\n",
    "    \n",
    "    \n",
    "class LocusCollection:\n",
    "    def __init__(self,loci,windowSize):\n",
    "        self.__chrToCoordToLoci = dict()\n",
    "        self.__loci = dict()\n",
    "        self.__winSize = windowSize\n",
    "        for lcs in loci: self.__addLocus(lcs)\n",
    "\n",
    "    def __addLocus(self,lcs):\n",
    "        if not(self.__loci.__contains__(lcs)):\n",
    "            self.__loci[lcs] = None\n",
    "            if lcs.sense()=='.': chrKeyList = [lcs.chr()+'+', lcs.chr()+'-']\n",
    "            else: chrKeyList = [lcs.chr()+lcs.sense()]\n",
    "            for chrKey in chrKeyList:\n",
    "                if not(self.__chrToCoordToLoci.__contains__(chrKey)): self.__chrToCoordToLoci[chrKey] = dict()\n",
    "                for n in self.__getKeyRange(lcs):\n",
    "                    if not(self.__chrToCoordToLoci[chrKey].__contains__(n)): self.__chrToCoordToLoci[chrKey][n] = []\n",
    "                    self.__chrToCoordToLoci[chrKey][n].append(lcs)\n",
    "    def __getKeyRange(self,locus):\n",
    "        start = int(locus.start() / self.__winSize)\n",
    "        end = int(locus.end() / self.__winSize) + 1\n",
    "        return range(start,end)\n",
    "    def __len__(self): return len(self.__loci)\n",
    "        \n",
    "    def append(self,new): self.__addLocus(new)\n",
    "    def extend(self,newList):\n",
    "        for lcs in newList: self.__addLocus(lcs)\n",
    "    def hasLocus(self,locus):\n",
    "        return self.__loci.__contains__(locus)\n",
    "    def remove(self,old):\n",
    "        if not(self.__loci.__contains__(old)): raise ValueError(\"requested locus isn't in collection\")\n",
    "        del self.__loci[old]\n",
    "        if old.sense()=='.': senseList = ['+','-']\n",
    "        else: senseList = [old.sense()]\n",
    "        for k in self.__getKeyRange(old):\n",
    "            for sense in senseList:\n",
    "                self.__chrToCoordToLoci[old.chr()+sense][k].remove(old)\n",
    "    def getWindowSize(self): return self.__winSize\n",
    "    def getLoci(self): return self.__loci.keys()\n",
    "    def getChrList(self):\n",
    "        tempKeys = dict()\n",
    "        for k in self.__chrToCoordToLoci.keys(): tempKeys[k[:-1]] = None\n",
    "        return tempKeys.keys()\n",
    "            \n",
    "    def __subsetHelper(self,locus,sense):\n",
    "        sense = sense.lower()\n",
    "        if ['sense','antisense','both'].count(sense)!=1:\n",
    "            raise ValueError(\"sense command invalid: '\"+sense+\"'.\")\n",
    "        matches = dict()\n",
    "        senses = ['+','-']\n",
    "        if locus.sense()=='.' or sense=='both': lamb = lambda s: True\n",
    "        elif sense=='sense': lamb = lambda s: s==locus.sense()\n",
    "        elif sense=='antisense': lamb = lambda s: s!=locus.sense()\n",
    "        else: raise ValueError(\"sense value was inappropriate: '\"+sense+\"'.\")\n",
    "        for s in filter(lamb, senses):\n",
    "            chrKey = locus.chr()+s\n",
    "            if self.__chrToCoordToLoci.__contains__(chrKey):\n",
    "                for n in self.__getKeyRange(locus):\n",
    "                    if self.__chrToCoordToLoci[chrKey].__contains__(n):\n",
    "                        for lcs in self.__chrToCoordToLoci[chrKey][n]:\n",
    "                            matches[lcs] = None\n",
    "        return matches.keys()\n",
    "    def getOverlap(self,locus,sense='sense'):\n",
    "        matches = self.__subsetHelper(locus,sense)\n",
    "        realMatches = dict()\n",
    "        if sense=='sense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.overlaps(locus), matches):\n",
    "                realMatches[i] = None\n",
    "        if sense=='antisense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.overlapsAntisense(locus), matches):\n",
    "                realMatches[i] = None \n",
    "        return realMatches.keys()\n",
    "    def getContained(self,locus,sense='sense'):\n",
    "        matches = self.__subsetHelper(locus,sense)\n",
    "        realMatches = dict()\n",
    "        if sense=='sense' or sense=='both':\n",
    "            for i in filter(lambda lcs: locus.contains(lcs), matches):\n",
    "                realMatches[i] = None\n",
    "        if sense=='antisense' or sense=='both':\n",
    "            for i in filter(lambda lcs: locus.containsAntisense(lcs), matches):\n",
    "                realMatches[i] = None\n",
    "        return realMatches.keys()\n",
    "    def getContainers(self,locus,sense='sense'):\n",
    "        matches = self.__subsetHelper(locus,sense)\n",
    "        realMatches = dict()\n",
    "        if sense=='sense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.contains(locus), matches):\n",
    "                realMatches[i] = None\n",
    "        if sense=='antisense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.containsAntisense(locus), matches):\n",
    "                realMatches[i] = None\n",
    "        return realMatches.keys()\n",
    "    def stitchCollection(self,stitchWindow=1,sense='both'):\n",
    "        locusList = self.getLoci()\n",
    "        oldCollection = LocusCollection(locusList,500)\n",
    "        stitchedCollection = LocusCollection([],500)\n",
    "        for locus in locusList:\n",
    "            if oldCollection.hasLocus(locus):\n",
    "                oldCollection.remove(locus)\n",
    "                overlappingLoci = oldCollection.getOverlap(Locus(locus.chr(),locus.start()-stitchWindow,locus.end()+stitchWindow,locus.sense(),locus.ID()),sense)\n",
    "                stitchTicker = 1\n",
    "                while len(overlappingLoci) > 0:\n",
    "                    stitchTicker+=len(overlappingLoci)\n",
    "                    overlapCoords = locus.coords()\n",
    "                    for overlappingLocus in overlappingLoci:\n",
    "                        overlapCoords+=overlappingLocus.coords()\n",
    "                        oldCollection.remove(overlappingLocus)\n",
    "                    if sense == 'both':\n",
    "                        locus = Locus(locus.chr(),min(overlapCoords),max(overlapCoords),'.',locus.ID())\n",
    "                    else:\n",
    "                        locus = Locus(locus.chr(),min(overlapCoords),max(overlapCoords),locus.sense(),locus.ID())\n",
    "                    overlappingLoci = oldCollection.getOverlap(Locus(locus.chr(),locus.start()-stitchWindow,locus.end()+stitchWindow,locus.sense()),sense)\n",
    "                locus._ID = '%s_%s_lociStitched' % (stitchTicker,locus.ID())\n",
    "                stitchedCollection.append(locus)\n",
    "            else:\n",
    "                continue\n",
    "        return stitchedCollection\n",
    "    def getLoci(self): return self.__loci.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0916d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e95731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "## for refseqToNameDict\n",
    "annotationFile = './CRCmapper/CRCmapper_package/annotation/hg19_refseq_NM.ucsc'\n",
    "annotTable = parseTable(annotationFile, '\\t')\n",
    "\n",
    "## refseqToNameDict\n",
    "refseqToNameDict = {}\n",
    "for line in annotTable[1:]:\n",
    "    gid = line[1]\n",
    "    genename = line[12].upper()\n",
    "    refseqToNameDict[gid] = genename\n",
    "# print(dict(list(refseqToNameDict.items())[0:5]))\n",
    "\n",
    "## SuperTable\n",
    "superFile = './ROSE/2.rose_Beta_narrow.05_broad.1_incltss/Beta_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "\n",
    "## SuperTable changed to tadTable\n",
    "tadFile = './hg19.GSE63525_GM12878_50K.TopDom_10.bed'\n",
    "tadTable = parseTable(tadFile, '\\t')\n",
    "for i in range(1, len(tadTable)+1):\n",
    "    tadTable[i-1].append(f'hg19_TAD_{i}')\n",
    "### chr start end type name \n",
    "## 3139\n",
    "\n",
    "## enhancerNumber\n",
    "## enhancerNumber = 500\n",
    "\n",
    "## expressionTable\n",
    "# expressionFile = './CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500/matrix.gff'\n",
    "# expressionFile = './CRCmapper/1-1.crc_HI-32_K27ac_incltss/matrix.gff'\n",
    "# expressionTable = parseTable(expressionFile, '\\t')\n",
    "\n",
    "## TFfile\n",
    "TFfile = './CRCmapper/CRCmapper_package/TFlist_NMid_hg.txt'\n",
    "TFtable = parseTable(TFfile, '\\t')\n",
    "TFlist = [line[0] for line in TFtable]\n",
    "TFlistGene = [line[1] for line in TFtable]\n",
    "\n",
    "## subpeaks\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_Beta_narrow.05_broad.1/Beta_peaks.broadPeak'\n",
    "# subpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\n",
    "\n",
    "## genomeDirectory FASTA (DNA sequences)\n",
    "genomeDirectory = './CRCmapper/hg19/'\n",
    "\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "\n",
    "## expCutoff: top 2/3 of the genes are considered to be expressed\n",
    "## expCutoff = 33\n",
    "\n",
    "## Transfac.v$ZIC2_01 ZIC2\n",
    "motifConvertFile = './CRCmapper/CRCmapper_package/MotifDictionary.txt'\n",
    "# motifDatabase = parseTable(motifConvertFile, '\\t')\n",
    "\n",
    "## PWM (motifDatabaseFile)\n",
    "PWMfile = './CRCmapper/CRCmapper_package/VertebratePWMs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "deccb089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 1-1. CRUP_HI-32_K27ac_incltss_cutoffSE_ext0\\n## enhancerNumber\\nEnumber = 'SE'\\n## motifExtension\\nmotifExtension = 0\\n## working directory\\nprojectFolder = f'./CRCmapper/1-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/'\\nprojectName = 'CRUP_HI-32_K27ac'\\n## SuperTable\\nsuperFile = './ROSE/1-1.rose_CRUP_HI-32_K27ac_incltss/islets_AllEnhancers.table.txt'\\nsuperTable = parseTable(superFile, '\\t')\\n## subpeak\\nsubpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\\n## expressionTable\\nexpressedNMfile = f'./CRCmapper/1-1.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2-2-TAD-TRAP.Beta_narrow.05_broad.1_incltss_cutoff500_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 500\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-2-TAD-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'Beta'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2.rose_Beta_narrow.05_broad.1_incltss/Beta_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_Beta_narrow.05_broad.1/Beta_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext{motifExtension}/Beta_EXPRESSED_TRANSCRIPTS.txt'\n",
    "\n",
    "\n",
    "'''\n",
    "# 2-2-TAD-TRAP.Beta_narrow.05_broad.1_incltss_cutoff500_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 500\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-2-TAD-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'Beta'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2.rose_Beta_narrow.05_broad.1_incltss/Beta_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_Beta_narrow.05_broad.1/Beta_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext500/Beta_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 3-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'  # 668\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/3-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/3-1.rose_CRUP_HI-32_K27ac_incltss_peakCutoff.8/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh_peakCutoff.8.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext500/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 3-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'  # 668\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/3-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/3-1.rose_CRUP_HI-32_K27ac_incltss_peakCutoff.8/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh_peakCutoff.8.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 2-1-TAD-TRAP.macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-1-TAD-TRAP.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'macs2_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2-1.rose_macs2_HI-32_K27ac_narrow.05_broad.05_incltss/H3K27ac_HI-32_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_HI-32_K27ac_narrow.05_broad.05/H3K27ac_HI-32_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-1.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 2-1. macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-1-TAD-TRAP.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'macs2_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2-1.rose_macs2_HI-32_K27ac_narrow.05_broad.05_incltss/H3K27ac_HI-32_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_HI-32_K27ac_narrow.05_broad.05/H3K27ac_HI-32_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-1.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext500/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 6-1-TAD-TRAP.crc_DE_narrow.05_broad.05_exclNMtss_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/6-1-TAD-TRAP.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'DE'\n",
    "## SuperTable\n",
    "superFile = './ROSE/6.rose_DE_narrow.05_broad.05_exclNMtss/DE_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_DE_narrow.05_broad.05/DE_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/6-1.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext{motifExtension}/DE_H3K27ac_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 6-1-TAD-TRAP.crc_DE_narrow.05_broad.05_exclNMtss_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/6-1-TAD-TRAP.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'DE'\n",
    "## SuperTable\n",
    "superFile = './ROSE/6.rose_DE_narrow.05_broad.05_exclNMtss/DE_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_DE_narrow.05_broad.05/DE_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/6-1.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext500/DE_H3K27ac_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "\n",
    "'''# 1-1-TAD-TRAP. CRUP_HI-32_K27ac_incltss_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/1-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/1-1.rose_CRUP_HI-32_K27ac_incltss/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/1-1.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 1-1. CRUP_HI-32_K27ac_incltss_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/1-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/1-1.rose_CRUP_HI-32_K27ac_incltss/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/1-1.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b14d85",
   "metadata": {},
   "source": [
    "## .1 createTADLoci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59367f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTADLoci(tadTable, tadType='domain'):\n",
    "    '''\n",
    "    takes as input a ROSE SuperEnhancer table \n",
    "    output a table of loci for SuperEnhancers\n",
    "    '''\n",
    "\n",
    "    print('CREATING TAD LOCUS COLLECTION')\n",
    "\n",
    "    output = []\n",
    "    if tadType == 'domain':\n",
    "        \n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        count3 = 0\n",
    "        count4 = 0\n",
    "        \n",
    "        \n",
    "        for line in tadTable:\n",
    "            if line[3] == 'domain':\n",
    "                # extend the region\n",
    "                if int(line[1]) >= 50000:\n",
    "                    locus = Locus(line[0], int(line[1]) - 50000, int(line[2]) + 50000, '.', line[4], float(0))\n",
    "                else:\n",
    "                    locus = Locus(line[0], int(line[1]), int(line[2]) + 50000, '.', line[4], float(0))\n",
    "                \n",
    "                gapOverlaps = gapCollection.getOverlap(locus)\n",
    "                \n",
    "                if len(gapOverlaps) != 0:  \n",
    "                    # if there's overlap between gap and extended domain, \n",
    "                    # then take the original domain without extension\n",
    "                    # print(len(gapOverlaps))\n",
    "                    # first recover the non-extended domain,\n",
    "                    # then extend the domain until it reaches a gap.\n",
    "                    minStart = int(locus.start()) + 50000\n",
    "                    maxEnd = int(locus.end()) - 50000\n",
    "                    \n",
    "                    # 最小的tad start是原始domain start左侧 and extended domain start右侧这段区间中，最大的gap.end()\n",
    "                    # 最大的tad end 是原始domain end右侧 and extended domain end左侧这段区间中，最小的gap.start()\n",
    "                    minStart = max([int(gap.end()) for gap in gapOverlaps if int(gap.end()) <= minStart], default = minStart - 50000)\n",
    "                    maxEnd = min([int(gap.start()) for gap in gapOverlaps if int(gap.start()) >= maxEnd], default = maxEnd + 50000)\n",
    "                    \n",
    "                    locus2 = Locus(line[0], minStart, maxEnd, '.', line[4], float(0))\n",
    "                    # if locus != locus2:\n",
    "                        # print(locus2.__str__())\n",
    "                    locus = Locus(line[0], minStart, maxEnd, '.', line[4], float(0))\n",
    "                    \n",
    "                    boundaryOverlaps = boundaryCollection.getOverlap(locus)\n",
    "                    \n",
    "                    if len(boundaryOverlaps) != 0: \n",
    "                        # overlap with gaps and boudnaries\n",
    "                        # if there's overlap between boundary and extended domain\n",
    "                        # then extend the domain to include the overlapped boundary\n",
    "                        \n",
    "                        minStart = int(locus.start())\n",
    "                        maxEnd = int(locus.end())\n",
    "                        \n",
    "                        # 最小tad start是与其重叠的boundary中，最小的boundary.start()\n",
    "                        # 最大的tad end是与其重叠的boundary中，最大的boudnary.end()\n",
    "                        # iteratively update start position of the region,\n",
    "                        # to get the largest merged tad region\n",
    "                        minStart = min([int(boundary.start()) for boundary in boundaryOverlaps if int(boundary.start()) < minStart], default = minStart)\n",
    "                        maxEnd = max([int(boundary.end()) for boundary in boundaryOverlaps if int(boundary.end()) > maxEnd], default = maxEnd)\n",
    "                        \n",
    "                        locus = Locus(line[0], minStart, maxEnd, '.', line[4], float(0))\n",
    "                        output.append(locus)\n",
    "                        count1 += 1\n",
    "                        \n",
    "                        # if len(gapCollection.getOverlap(locus)) != 0:\n",
    "                            # print('gap True, boundary True: ', locus.__str__(), len(gapCollection.getOverlap(locus)))\n",
    "                    else:\n",
    "                        # overlap with gaps, but not with boundaries\n",
    "                        output.append(locus)\n",
    "                        count2 += 1\n",
    "                        # if len(gapCollection.getOverlap(locus)) != 0:\n",
    "                            # print('gap True, boundary False: ', locus.__str__(), len(gapCollection.getOverlap(locus)))\n",
    "                    \n",
    "                else:\n",
    "                    # if there's no overlap between gap and extended domain, \n",
    "                    # then take the extended domain\n",
    "                    # print(locus)\n",
    "                    boundaryOverlaps = boundaryCollection.getOverlap(locus)\n",
    "                    \n",
    "                    if len(boundaryOverlaps) != 0:\n",
    "                        # not overlap with gaps, but with boundaries\n",
    "                        # there's overlap between boundary and extended domain,\n",
    "                        # then take the merged region\n",
    "                        # print(len(boundaryOverlaps))\n",
    "                        \n",
    "                        minStart = int(locus.start())\n",
    "                        maxEnd = int(locus.end())\n",
    "                        \n",
    "                        minStart = min([int(boundary.start()) for boundary in boundaryOverlaps if int(boundary.start()) < minStart], default = minStart)\n",
    "                        maxEnd = max([int(boundary.end()) for boundary in boundaryOverlaps if int(boundary.end()) > maxEnd], default = maxEnd)\n",
    "                        \n",
    "                        locus = Locus(line[0], minStart, maxEnd, '.', line[4], float(0))\n",
    "                        output.append(locus)\n",
    "                        count3 += 1\n",
    "                        # if len(gapCollection.getOverlap(locus)) != 0:\n",
    "                            # print('gap False, boundary True: ', locus.__str__(), len(gapCollection.getOverlap(locus)))\n",
    "                    \n",
    "                    else:\n",
    "                        # not overlap with gaps and boundaries, which means it overlaps with a domain\n",
    "                        output.append(locus)\n",
    "                        count4 += 1\n",
    "\n",
    "        print('gap \\t boudary \\t #')\n",
    "        print(f'True \\t True \\t {count1}')\n",
    "        print(f'True \\t False \\t {count2}')\n",
    "        print(f'False \\t True \\t {count3}')\n",
    "        print(f'False \\t False \\t {count4}')\n",
    "        print(f'total \\t  \\t {count1 + count2 + count3 + count4}')\n",
    "        \n",
    "        \n",
    "    elif tadType == 'boundary':\n",
    "        for line in tadTable:\n",
    "            if line[3] == 'boundary':\n",
    "                locus = Locus(line[0], line[1], line[2], '.', line[4], float(0))\n",
    "                output.append(locus)\n",
    "    elif tadType == 'gap':\n",
    "        for line in tadTable:\n",
    "            if line[3] == 'gap':\n",
    "                locus = Locus(line[0], line[1], line[2], '.', line[4], float(0))\n",
    "                output.append(locus)\n",
    "    else:\n",
    "        print('error!')\n",
    "                \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12a3a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING TAD LOCUS COLLECTION\n",
      "chr1(.):0-700000 chr1(.):3850000-3950000 chr1(.):13000000-13750000 chr1(.):24300000-24350000 chr1(.):29900000-30000000\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "gapLoci = createTADLoci(tadTable, 'gap')\n",
    "gapCollection = LocusCollection(gapLoci, 50)\n",
    "print(*gapLoci[:5])\n",
    "print(len(gapLoci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b802a8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING TAD LOCUS COLLECTION\n",
      "chr1(.):1300000-1650000 chr1(.):1650000-1850000 chr1(.):7800000-8000000 chr1(.):9650000-9950000 chr1(.):11850000-12150000\n",
      "1081\n"
     ]
    }
   ],
   "source": [
    "boundaryLoci = createTADLoci(tadTable, 'boundary')\n",
    "boundaryCollection = LocusCollection(boundaryLoci, 50)\n",
    "print(*boundaryLoci[:5])\n",
    "print(len(boundaryLoci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2939a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING TAD LOCUS COLLECTION\n",
      "gap \t boudary \t #\n",
      "True \t True \t 71\n",
      "True \t False \t 222\n",
      "False \t True \t 1213\n",
      "False \t False \t 1633\n",
      "total \t  \t 3139\n",
      "chr1(.):700000-1650000 chr1(.):1650000-2650000 chr1(.):2550000-3400000 chr1(.):3300000-3850000 chr1(.):3950000-6050000\n",
      "3139\n"
     ]
    }
   ],
   "source": [
    "tadLoci = createTADLoci(tadTable, 'domain')\n",
    "tadCollection = LocusCollection(tadLoci, 50)\n",
    "print(*tadLoci[:5])\n",
    "print(len(tadLoci))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c361b058-f13b-431c-a5f6-4ee6ec44c844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1(.):700000-3850000 chr1(.):3950000-13000000 chr1(.):13750000-15650000 chr1(.):15850000-24300000 chr1(.):24350000-27600000\n"
     ]
    }
   ],
   "source": [
    "# stitch overlapped TAD\n",
    "stitchedTADCollection = tadCollection.stitchCollection()\n",
    "print(*list(stitchedTADCollection.getLoci())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "4acfb98f-4807-4b8b-858e-94be11463cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total hg19 chromSizes: \t 3,036,303,846\n"
     ]
    }
   ],
   "source": [
    "with open('./ChIP-seq/Meissner/hg19.chrom.sizes', 'r') as f:\n",
    "    chrom = ['chr'+str(i) for i in range(1, 23)] + ['chrX']\n",
    "    chromLen1 = 0\n",
    "    lines = f.readlines()\n",
    "    for i in range(0, len(lines)):\n",
    "        line = lines[i].replace('\\n', '').split('\\t')\n",
    "        if line[0] in chrom:\n",
    "            chromLen1 += int(line[1])\n",
    "            \n",
    "    print(f'total hg19 chromSizes: \\t {chromLen1:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "de64b18c-9cc9-459b-9231-9613c78afe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total hg19 TAD without gaps: \t  2,803,136,782\n"
     ]
    }
   ],
   "source": [
    "with open('./hg19.GSE63525_GM12878_50K.TopDom_10.bed', 'r') as f:\n",
    "    chromLen2 = 0\n",
    "    lines = f.readlines()\n",
    "    for i in range(0, len(lines)):\n",
    "        line = lines[i].replace('\\n', '').split('\\t')\n",
    "        if line[3] != 'gap':\n",
    "            chromLen2 += int(line[2]) - int(line[1])\n",
    "            \n",
    "    print(f'total hg19 TAD without gaps: \\t {chromLen2: ,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "409fe57d-0972-4e66-9fd5-db5c58dc0409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total TAD length: \t  2,770,736,782\n"
     ]
    }
   ],
   "source": [
    "# check the coverage of generated TAD\n",
    "chromLen3 = 0\n",
    "for loci in stitchedTADCollection.getLoci():\n",
    "    chromLen3 += loci.coords()[1] - loci.coords()[0]\n",
    "print(f'total TAD length: \\t {chromLen3: ,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "8753a102-b363-4274-8646-0aad19d6f57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TAD / all hg19 TAD: \t  0.988\n",
      "TAD / hg19 genome: \t  0.913\n"
     ]
    }
   ],
   "source": [
    "print(f'TAD / all hg19 TAD: \\t {chromLen3/chromLen2: .3f}')\n",
    "print(f'TAD / hg19 genome: \\t {chromLen3/chromLen1: .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9c90b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSuperLoci(superTable, Enumber='super'):\n",
    "    '''\n",
    "    takes as input a ROSE SuperEnhancer table \n",
    "    output a table of loci for SuperEnhancers\n",
    "    '''\n",
    "    \n",
    "    print('CREATING SUPER-ENHANCER LOCUS COLLECTION')\n",
    "    \n",
    "    output = []\n",
    "\n",
    "    if Enumber == 'super':\n",
    "        for line in superTable[6:]:\n",
    "            if line[-1] == '1':\n",
    "                locus = Locus(line[1], line[2], line[3], '.', line[0], (float(line[6])-float(line[7])))\n",
    "                output.append(locus)\n",
    "    else:\n",
    "        end = 6+int(Enumber)\n",
    "        for line in superTable[6:end]:\n",
    "            locus = Locus(line[1], line[2], line[3], '.', line[0], (float(line[6])-float(line[7])))\n",
    "            output.append(locus)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81f2bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING SUPER-ENHANCER LOCUS COLLECTION\n",
      "chr8(.):118136600-118286400 chr17(.):2689300-2887300 chr10(.):79044600-79291900 chr12(.):124837100-125053500 chr10(.):80818000-80957700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "668"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# superLoci = createSuperLoci(superTable)\n",
    "superLoci = createSuperLoci(superTable)\n",
    "print(*superLoci[:5])\n",
    "len(superLoci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4a7ec",
   "metadata": {},
   "source": [
    "## .2 creatExpressionDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a099754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14739\n",
      "./CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500/Beta_EXPRESSED_TRANSCRIPTS.txt\n"
     ]
    }
   ],
   "source": [
    "# expressedNM = createExpressionDict(annotationFile, projectFolder, projectName, refseqToNameDict, expressionTable)\n",
    "# expressedNMfile = './CRCmapper/1-1.crc_HI-32_K27ac_incltss_noExtension/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "# expressedNMfile = './CRCmapper/1-1.crc_HI-32_K27ac_incltss/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "expressedNMfile = './CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500/Beta_EXPRESSED_TRANSCRIPTS.txt'\n",
    "# expressedNMfile = f'./CRCmapper/3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext500/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "with open(expressedNMfile, \"r\") as f:\n",
    "    expressedNM = [line.rstrip('\\n') for line in f]\n",
    "print(len(expressedNM))\n",
    "print(expressedNMfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d05ea52b-00ea-4853-90b0-2dff8746629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "821\n"
     ]
    }
   ],
   "source": [
    "expressedGenes = uniquify([refseqToNameDict[gene] for gene in expressedNM if gene in TFlist])\n",
    "print(len(expressedGenes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c77fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createExpressionDict(annotationFile, projectFolder, projectName, refseqToNameDict,expressionTable):\n",
    "    \n",
    "    takes as input an activity table with refseq NMID in first column and expression or promoter\n",
    "    acetylation level in a second column\n",
    "    output a dictionary keyed by refseq containing activity\n",
    "\n",
    "    print('CREATING EXPRESSION DICTIONARY')\n",
    "\n",
    "    annotTable = parseTable(annotationFile, '\\t')\n",
    "    for line in annotTable:\n",
    "        gid = line[1]\n",
    "        genename = line[12].upper()\n",
    "        refseqToNameDict[gid] = genename\n",
    "\n",
    "    expresionFilename = projectFolder + 'matrix.gff'\n",
    "    expressionTable = parseTable(expresionFilename, '\\t')\n",
    "\n",
    "    expressionDictNM = {}\n",
    "    expressionDictGene = {}\n",
    "\n",
    "    for line in expressionTable[1:]:\n",
    "        trid = line[0]\n",
    "        geneName = refseqToNameDict[trid]\n",
    "        if len(expressionTable[1]) == 3: #when expressionTable is an output from bamToGFF.py\n",
    "                exp = float(line[2])\n",
    "        else: #when expressionTable is passed as an option (2 columns)\n",
    "                exp = float(line[1])\n",
    "\n",
    "        # Store the expression value for each NMid in a dict, keep higher value if multiple identical NMIDs\n",
    "        if trid in expressionDictNM and exp > expressionDictNM[trid]:\n",
    "            expressionDictNM[trid] = exp\n",
    "        elif trid not in expressionDictNM:\n",
    "            expressionDictNM[trid] = exp\n",
    "\n",
    "        # Store the highest value of transcript expression for each gene\n",
    "        if geneName in expressionDictGene and exp > expressionDictGene[geneName]:\n",
    "            expressionDictGene[geneName] = exp\n",
    "        elif geneName not in expressionDictGene:\n",
    "            expressionDictGene[geneName] = exp\n",
    "    \n",
    "    expressedGenes = []\n",
    "    expressedNM = []\n",
    "    for trid in expressionDictNM:\n",
    "        expressedGenes.append(refseqToNameDict[trid])\n",
    "        expressedNM.append(trid)\n",
    "    expressedGenes = uniquify(expressedGenes)\n",
    "    \n",
    "    return expressedNM, expressedGenes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cc7c232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING EXPRESSION DICTIONARY\n"
     ]
    }
   ],
   "source": [
    "expressedNM, expressedGenes = createExpressionDict(annotationFile, './CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500/', projectName, refseqToNameDict, expressionTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fe560",
   "metadata": {},
   "source": [
    "## .3 findCanidateTFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3807b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCanidateTFs(annotationFile, tadLoci, expressedNM, TFlist, refseqToNameDict):\n",
    "    '''\n",
    "    find all TFs that are considered expressed within a TAD\n",
    "    return a dictionary keyed by TAD loci that points to a list of TFs that are contained within the TAD\n",
    "    '''\n",
    "\n",
    "    print('FINDING CANIDATE TFs')\n",
    "    \n",
    "    startDict = makeStartDict(annotationFile)\n",
    "    \n",
    "    # Find the location of the TSS of all transcripts (NMid) considered expressed\n",
    "    tssLoci = []\n",
    "    for geneID in expressedNM:\n",
    "        tssLoci.append(makeTSSLocus(geneID,startDict,0,0))  # 1bp region\n",
    "    tssCollection = LocusCollection(tssLoci,50)\n",
    "\n",
    "    # Assign all transcripts (NMid) that are TFs to a TAD if it is within the TAD\n",
    "    tadAssignment = []\n",
    "    tadAssignmentGene = []\n",
    "    TFandTADdict = {}\n",
    "    \n",
    "    for tad in tadLoci:\n",
    "        \n",
    "        # Find all transcripts whose TSS occur within a TAD\n",
    "        searchLocus = Locus(tad.chr(), tad.start(), tad.end(), '.')\n",
    "        allEnhancerLoci = tssCollection.getOverlap(searchLocus)\n",
    "        allEnhancerGenes = [locus.ID() for locus in allEnhancerLoci]\n",
    "        \n",
    "        geneName = uniquify([refseqToNameDict[gene] for gene in allEnhancerGenes if gene in TFlist])\n",
    "        \n",
    "        # Select the transcript if it is a TF, and allow for a TAD to have multiple TF genes inside\n",
    "        if geneName != []:\n",
    "            for gene in allEnhancerGenes:\n",
    "                if gene in TFlist and tad not in TFandTADdict.keys():\n",
    "                    TFandTADdict[tad] = [gene]\n",
    "                elif gene in TFlist and tad in TFandTADdict.keys():\n",
    "                    TFandTADdict[tad].append(gene)\n",
    "            tadAssignment.append([tad.chr(), tad.start(), tad.end(), TFandTADdict[tad]])\n",
    "            tadAssignmentGene.append([tad.chr(), tad.start(), tad.end(), geneName])\n",
    "        else:\n",
    "            TFandTADdict[tad] = []\n",
    "    \n",
    "    print(f'Number of TADs that contains TF genes: {len(tadAssignment)}, {len(tadAssignmentGene)}')\n",
    "    \n",
    "\n",
    "    return tadAssignment, tadAssignmentGene, TFandTADdict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6565929c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINDING CANIDATE TFs\n",
      "Number of TADs that contains TF genes: 564, 564\n"
     ]
    }
   ],
   "source": [
    "# TAD domain\n",
    "tadAssignment, tadAssignmentGene, TFandTADdict = findCanidateTFs(annotationFile, tadLoci, expressedNM, TFlist, refseqToNameDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c9b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['chr1', 700000, 1650000, ['NM_021170']],\n",
       " ['chr1', 2550000, 3400000, ['NM_199454']],\n",
       " ['chr1', 5950000, 6800000, ['NM_005341']],\n",
       " ['chr1', 6700000, 8000000, ['NM_001195563']],\n",
       " ['chr1', 7800000, 8500000, ['NM_001042682']]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tadAssignment))\n",
    "tadAssignment[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7435d559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['chr1', 700000, 1650000, ['HES4']],\n",
       " ['chr1', 2550000, 3400000, ['PRDM16']],\n",
       " ['chr1', 5950000, 6800000, ['ZBTB48']],\n",
       " ['chr1', 6700000, 8000000, ['CAMTA1']],\n",
       " ['chr1', 7800000, 8500000, ['RERE']]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tadAssignmentGene))\n",
    "tadAssignmentGene[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e45acea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{<__main__.Locus at 0x7fbff2e09750>: ['NM_021170'],\n",
       " <__main__.Locus at 0x7fc01216d4e0>: [],\n",
       " <__main__.Locus at 0x7fbff2e18be0>: ['NM_199454'],\n",
       " <__main__.Locus at 0x7fbff252be50>: [],\n",
       " <__main__.Locus at 0x7fbff252b790>: []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(TFandTADdict))\n",
    "dict(list(TFandTADdict.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32b5d2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chr16', 3050000, 3600000, ['ZNF205', 'ZNF213', 'ZNF263', 'ZNF75A', 'ZNF174', 'ZNF200', 'ZNF597']]\n",
      "['chr19', 8350000, 10200000, ['ZNF317', 'ZNF559', 'ZNF266', 'ZNF426', 'ZNF121', 'ZNF561', 'ZNF562']]\n",
      "['chr19', 11350000, 13050000, ['ZNF627', 'ZNF441', 'ZNF491', 'ZNF440', 'ZNF69', 'ZNF700', 'ZNF136', 'JUNB', 'ZNF653', 'ZNF823', 'ZNF433', 'ZNF20', 'ZNF625', 'ZNF44', 'ZNF563', 'ZNF442', 'ZNF443', 'ZNF709', 'ZNF490']]\n",
      "['chr19', 19650000, 24650000, ['ZNF101', 'ZNF93', 'ZNF90', 'ZNF85', 'ZNF430', 'ZNF714', 'ZNF431', 'ZNF493', 'ZNF257', 'ZNF726', 'ZNF254', 'PBX4', 'ZNF14', 'ZNF506', 'ZNF682', 'ZNF626', 'ZNF708', 'ZNF100', 'ZNF43', 'ZNF208', 'ZNF91', 'ZNF675', 'ZNF681']]\n",
      "['chr19', 36650000, 38400000, ['ZNF146', 'ZNF382', 'ZNF567', 'ZNF568', 'ZNF420', 'HKR1', 'ZNF527', 'ZNF570', 'ZNF540', 'ZNF565', 'ZFP14', 'ZNF566', 'ZNF529', 'ZNF461', 'ZNF585A', 'ZNF569', 'ZNF571', 'ZFP30', 'ZNF607', 'ZNF573']]\n",
      "['chr19', 43900000, 45350000, ['ZNF575', 'ZNF576', 'ZNF221', 'ZNF155', 'ZNF230', 'ZNF222', 'ZNF223', 'ZNF284', 'ZNF226', 'ZNF227', 'ZNF233', 'ZNF45', 'ZNF235', 'ZNF229', 'ZNF180']]\n",
      "['chr19', 52150000, 54650000, ['ZNF613', 'ZNF480', 'ZNF610', 'ZNF701', 'ZNF765', 'ZNF331', 'ZNF577', 'ZNF649', 'ZNF615', 'ZNF614', 'ZNF616', 'ZNF83', 'ZNF611', 'ZNF600', 'ZNF28', 'ZNF468', 'ZNF160', 'ZNF415', 'ZNF347', 'ZNF665', 'ZNF677']]\n",
      "['chr19', 55550000, 56250000, ['ZNF628', 'ZNF524', 'ZNF580', 'ZNF581', 'ZNF579', 'FIZ1']]\n",
      "['chr19', 56150000, 57700000, ['ZNF580', 'ZNF581', 'ZNF444', 'ZNF583', 'ZNF471', 'ZFP28', 'ZNF470', 'ZNF71', 'ZNF582', 'ZNF667', 'PEG3']]\n",
      "['chr19', 57600000, 59178983, ['ZNF264', 'ZNF460', 'ZNF543', 'ZNF304', 'ZNF547', 'ZNF548', 'ZNF17', 'ZNF749', 'ZNF419', 'ZNF549', 'ZIK1', 'ZNF530', 'ZNF134', 'ZNF211', 'ZNF551', 'ZNF586', 'ZNF587', 'ZSCAN1', 'ZNF135', 'ZNF274', 'ZNF544', 'ZNF8', 'ZSCAN22', 'ZNF584', 'ZNF324', 'ZNF446', 'ZNF416', 'ZNF671', 'ZNF552', 'ZNF417', 'ZNF418', 'ZNF256', 'ZNF606', 'ZSCAN18', 'ZNF329', 'ZNF497', 'ZNF132', 'ZBTB45', 'MZF1']]\n",
      "['chr3', 44300000, 45100000, ['ZNF660', 'ZNF197', 'ZNF35', 'ZNF502', 'ZNF501', 'ZNF445']]\n",
      "['chr6', 27850000, 28600000, ['ZNF165', 'ZSCAN16', 'ZKSCAN3', 'ZKSCAN4', 'ZSCAN12', 'ZSCAN23']]\n",
      "['chr7', 99000000, 100050000, ['ZKSCAN5', 'ZNF655', 'ZKSCAN1', 'ZSCAN21', 'ZNF394', 'ZNF3']]\n",
      "['chr7', 148700000, 149500000, ['ZNF398', 'ZNF282', 'ZNF212', 'ZNF783', 'ZNF425', 'ZNF777', 'ZNF746', 'ZNF467']]\n",
      "['chr8', 145650000, 146414022, ['ZNF517', 'ZNF7', 'ZNF251', 'ZNF34', 'ZNF250', 'ZNF16']]\n",
      "0: 2575, 4.57\n",
      "1: 443, 0.79\n",
      "2: 73, 0.13\n",
      "3: 19, 0.03\n",
      "4: 11, 0.02\n",
      "5: 3, 0.01\n",
      "6: 5, 0.01\n",
      "7: 2, 0.00\n",
      "8: 1, 0.00\n",
      "11: 1, 0.00\n",
      "15: 1, 0.00\n",
      "19: 1, 0.00\n",
      "20: 1, 0.00\n",
      "21: 1, 0.00\n",
      "23: 1, 0.00\n",
      "39: 1, 0.00\n",
      "549\n"
     ]
    }
   ],
   "source": [
    "# for visualization\n",
    "# {'# of genes in a TAD': '# of TADs that contain this number of genes'}\n",
    "countDict = {}\n",
    "for line in tadAssignmentGene:\n",
    "    l = len(uniquify(line[3]))\n",
    "    if l > 5:\n",
    "        print(line)\n",
    "    if l not in countDict.keys():\n",
    "        countDict[len(uniquify(line[3]))] = 1\n",
    "    else:\n",
    "        countDict[len(uniquify(line[3]))] += 1\n",
    "        \n",
    "countDict[0] = len(TFandTADdict) - len(tadAssignmentGene)\n",
    "\n",
    "for k, v in sorted(countDict.items()):\n",
    "    print(f'{k}: {v}, {v/len(tadAssignment):.2f}')\n",
    "\n",
    "print(sum([countDict[i] for i in range(1,6)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20a730f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of TADs that contain <= 5 expressed TF genes: 549\n"
     ]
    }
   ],
   "source": [
    "# create new dict: tads with <= 5 expressed TF genes\n",
    "# {tad: [geneNames]}\n",
    "newTFandTADdict = {}\n",
    "\n",
    "for tad, genes in TFandTADdict.items():\n",
    "    if len(genes) != 0:\n",
    "        geneNames = uniquify([refseqToNameDict[gene] for gene in genes if gene in TFlist])\n",
    "        if not len(geneNames) > 5:\n",
    "            newTFandTADdict[tad] = geneNames\n",
    "\n",
    "print(f'# of TADs that contain <= 5 expressed TF genes: {len(newTFandTADdict.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c3b1c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of expressed genes: \t 804\n",
      "# of candidate genes: \t 590\n",
      "# of non-recovered genes: \t 214\n",
      "['ATF6B', 'CREB3L1', 'ELF3', 'ETV7', 'FEV', 'FIZ1', 'FOSL1', 'HKR1', 'JUNB', 'LBX2', 'MEF2D', 'MXD4', 'MZF1', 'NFKB2', 'PBX4', 'PEG3', 'RELA', 'RXRB', 'SIX5', 'SRY', 'TSC22D4', 'USF1', 'ZBTB12', 'ZBTB33', 'ZBTB45', 'ZFP14', 'ZFP28', 'ZFP30', 'ZFY', 'ZIK1', 'ZKSCAN1', 'ZKSCAN3', 'ZKSCAN4', 'ZKSCAN5', 'ZNF100', 'ZNF101', 'ZNF121', 'ZNF132', 'ZNF134', 'ZNF135', 'ZNF136', 'ZNF14', 'ZNF155', 'ZNF16', 'ZNF160', 'ZNF165', 'ZNF17', 'ZNF174', 'ZNF180', 'ZNF197', 'ZNF20', 'ZNF200', 'ZNF208', 'ZNF211', 'ZNF212', 'ZNF221', 'ZNF222', 'ZNF223', 'ZNF226', 'ZNF227', 'ZNF229', 'ZNF230', 'ZNF233', 'ZNF235', 'ZNF250', 'ZNF251', 'ZNF254', 'ZNF256', 'ZNF257', 'ZNF26', 'ZNF263', 'ZNF264', 'ZNF266', 'ZNF274', 'ZNF28', 'ZNF282', 'ZNF284', 'ZNF3', 'ZNF304', 'ZNF317', 'ZNF324', 'ZNF329', 'ZNF331', 'ZNF34', 'ZNF347', 'ZNF35', 'ZNF382', 'ZNF384', 'ZNF398', 'ZNF415', 'ZNF416', 'ZNF417', 'ZNF418', 'ZNF419', 'ZNF420', 'ZNF425', 'ZNF426', 'ZNF43', 'ZNF430', 'ZNF431', 'ZNF433', 'ZNF44', 'ZNF440', 'ZNF441', 'ZNF442', 'ZNF443', 'ZNF444', 'ZNF445', 'ZNF446', 'ZNF45', 'ZNF460', 'ZNF461', 'ZNF468', 'ZNF470', 'ZNF471', 'ZNF480', 'ZNF490', 'ZNF491', 'ZNF493', 'ZNF497', 'ZNF501', 'ZNF502', 'ZNF506', 'ZNF517', 'ZNF524', 'ZNF527', 'ZNF529', 'ZNF530', 'ZNF540', 'ZNF543', 'ZNF544', 'ZNF547', 'ZNF548', 'ZNF549', 'ZNF551', 'ZNF552', 'ZNF559', 'ZNF561', 'ZNF562', 'ZNF563', 'ZNF566', 'ZNF567', 'ZNF568', 'ZNF569', 'ZNF570', 'ZNF571', 'ZNF573', 'ZNF577', 'ZNF579', 'ZNF580', 'ZNF581', 'ZNF582', 'ZNF583', 'ZNF584', 'ZNF585A', 'ZNF586', 'ZNF587', 'ZNF597', 'ZNF600', 'ZNF606', 'ZNF607', 'ZNF610', 'ZNF611', 'ZNF613', 'ZNF614', 'ZNF615', 'ZNF616', 'ZNF625', 'ZNF626', 'ZNF627', 'ZNF628', 'ZNF649', 'ZNF653', 'ZNF655', 'ZNF658', 'ZNF660', 'ZNF665', 'ZNF667', 'ZNF671', 'ZNF675', 'ZNF677', 'ZNF681', 'ZNF682', 'ZNF69', 'ZNF7', 'ZNF700', 'ZNF701', 'ZNF708', 'ZNF709', 'ZNF71', 'ZNF710', 'ZNF714', 'ZNF726', 'ZNF746', 'ZNF749', 'ZNF75A', 'ZNF765', 'ZNF777', 'ZNF783', 'ZNF8', 'ZNF823', 'ZNF83', 'ZNF84', 'ZNF85', 'ZNF90', 'ZNF91', 'ZNF93', 'ZSCAN1', 'ZSCAN12', 'ZSCAN16', 'ZSCAN18', 'ZSCAN21', 'ZSCAN22', 'ZSCAN23']\n"
     ]
    }
   ],
   "source": [
    "# create candidate gene list that contains gene NAMEs. \n",
    "candidateGenes = set()\n",
    "\n",
    "for tad, genes in newTFandTADdict.items():\n",
    "    \n",
    "    # geneNames = uniquify([refseqToNameDict[gene] for gene in genes if gene in TFlist])\n",
    "    intersect = candidateGenes.intersection(genes)\n",
    "    \n",
    "    # print genes that are located in overlapped TAD\n",
    "    # if len(intersect) != 0:\n",
    "        # print(f'{tad.__str__()} \\t {len(intersect)} \\t {intersect}')\n",
    "    \n",
    "    candidateGenes.update(genes)\n",
    "\n",
    "print(f'# of expressed genes: \\t {len(expressedGenes)}')\n",
    "print(f'# of candidate genes: \\t {len(candidateGenes)}')  # candidates是包含在TAD里的genes, 该TAD包含的genes不超过5个\n",
    "print(f'# of non-recovered genes: \\t {len(set(expressedGenes) ^ set(candidateGenes))}')\n",
    "print(sorted(list(set(expressedGenes) ^ set(candidateGenes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c219df2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 {'FOXA3', 'MLX', 'ZNF467', 'ZNF77', 'SRF', 'ZNF32', 'NFYA', 'ZBTB2', 'DBP', 'ESR2', 'IRF1', 'KLF16', 'RCOR3', 'ZNF484', 'ETV3', 'ZNF664', 'SNAI1', 'MYBL1', 'ATF6', 'GLIS3', 'ESRRA', 'ZFHX2', 'TEF', 'ZNF57', 'ZNF24', 'ZNF662', 'E2F5', 'KLF11', 'ATF3', 'ZNF485'}\n",
      "94 {'IRF9', 'ZNF70', 'EGR4', 'IKZF4', 'NFIX', 'RARA', 'NOTO', 'NFKB2', 'IRF7', 'MESP2', 'MXD3', 'CREB3', 'FOXJ2', 'ATF5', 'ZNF653', 'TSC22D4', 'BATF2', 'ZNF410', 'FOXK1', 'NFE2L2', 'ZNF205', 'PPARD', 'ETV7', 'SIX5', 'NFYC', 'ZNF687', 'BCL6B', 'OVOL1', 'ZNF473', 'NFATC4', 'HHEX', 'NFX1', 'FEV', 'FOXK2', 'THRA', 'ZNF22', 'CREB3L1', 'WHSC1', 'JUND', 'MXD4', 'NR4A1', 'ZNF652', 'PREB', 'ZNF213', 'NKX3-1', 'GABPA', 'JUNB', 'ELF1', 'ZNF668', 'ID3', 'PRDM15', 'ZNF575', 'MEF2D', 'GRHL2', 'ADNP', 'FOXO4', 'RFX5', 'SCRT2', 'DDIT3', 'IRF3', 'ELK4', 'SNAPC4', 'NR1D1', 'ZNF384', 'PBX2', 'ZFP37', 'EGR1', 'RELA', 'DEAF1', 'ELF3', 'ID1', 'ATF7', 'SREBF2', 'ZNF576', 'HINFP', 'ZNF629', 'GMEB1', 'GLI1', 'LBX2', 'ZNF513', 'RXRB', 'ZNF646', 'ZSCAN20', 'FOSL1', 'MNT', 'ZBTB49', 'ZBTB33', 'ZNF710', 'MTF1', 'ZNF101', 'ZNF408', 'FOSB', 'FOXE1', 'USF1'}\n"
     ]
    }
   ],
   "source": [
    "boundaryGeneT = set()\n",
    "boundaryGeneF = set()\n",
    "\n",
    "for line in boundaryAssignmentGene:\n",
    "    intersect = candidateGenes.intersection(line[3])\n",
    "    if len(intersect) != 0:\n",
    "        boundaryGeneT.update(intersect)\n",
    "    else:\n",
    "        boundaryGeneF.update(line[3])\n",
    "\n",
    "print(len(boundaryGeneT), boundaryGeneT)\n",
    "print(len(boundaryGeneF), boundaryGeneF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc04037",
   "metadata": {},
   "source": [
    "---\n",
    "## .4 generateTRAPsubPeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a10e1d35-0749-445a-a548-e673ad34fd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subpeaks = SE subpeaks + remaining peaks in the TAD\n",
    "def generateSubpeakFASTA(TFandTADdict, superLoci, subpeaks, genomeDirectory, projectName, projectFolder, motifExtension):\n",
    "    '''\n",
    "    keep TADs that overlap SE, and output peaks in the TADs\n",
    "    '''\n",
    "    print('MAKE FASTA')\n",
    "    \n",
    "    # make bed file\n",
    "    subpeakDict = {}\n",
    "    subpeakBED = []\n",
    "    subpeakTable = parseTable(subpeaks, '\\t')\n",
    "    \n",
    "    # subpeakCollection contains all peaks called from macs2\n",
    "    subpeakLoci = [Locus(l[0], int(l[1]), int(l[2]), '.') for l in subpeakTable]\n",
    "    subpeakCollection = LocusCollection(subpeakLoci, 50)  # macs2 broadPeaks\n",
    "    \n",
    "    # tadLoci contains TADs that have 1-5 TF genes\n",
    "    tadLoci = list(TFandTADdict.keys())\n",
    "    tadCollection = LocusCollection(tadLoci, 50)\n",
    "    print(len(tadCollection.getLoci()))\n",
    "    \n",
    "    # subTADloci contains all TAD regions that have at least 1 TF gene\n",
    "    # subTADloci = [tad for tad in TFandTADdict.keys() if len(TFandTADdict[tad]) != 0]  # len(subTADloci)\n",
    "    # subTADcollection = LocusCollection(subTADloci, 50)\n",
    "    \n",
    "    used = {}\n",
    "    \n",
    "    for loci in superLoci:\n",
    "        overlappedTAD = list(tadCollection.getOverlap(loci))  # subTAD regions that fully contain 1 or more superLoci\n",
    "        \n",
    "        if not overlappedTAD: continue;  # if overlappedSE is empty 如果SE没有和任何TAD重叠\n",
    "            \n",
    "        else:  # if such tad exists\n",
    "            for tad in overlappedTAD:  # for loop is for the case that one SE overlap two or more TADs\n",
    "                if tad in used.keys(): \n",
    "                    print(loci.__str__(), tad.__str__())\n",
    "                    # continue;  # uniq subTAD_containing_SE\n",
    "                \n",
    "                # used[subTAD] = None\n",
    "                for gene in TFandTADdict[tad]:\n",
    "                    if gene not in subpeakDict.keys():\n",
    "                        subpeakDict[gene] = set()\n",
    "                    overlaps = set(subpeakCollection.getOverlap(tad))  # broadPeaks that overlap the TAD\n",
    "                    overlaps.update(subpeakCollection.getOverlap(loci))  # plus peaks that overlap the SE\n",
    "                    extendedOverlaps = [makeSearchLocus(x, motifExtension, motifExtension) for x in overlaps]  \n",
    "                    # extends the overlapped broadPeaks by motifExtension\n",
    "                    \n",
    "                    overlapCollectionTemp = LocusCollection(extendedOverlaps, 50)\n",
    "                    overlapCollection = overlapCollectionTemp.stitchCollection()  # links the overlapped broadPeaks that overlaps each other\n",
    "                    \n",
    "                    for overlap in overlapCollection.getLoci():\n",
    "                        pos = [overlap.chr(), overlap.start(), overlap.end()]\n",
    "                        if pos not in subpeakBED:\n",
    "                            subpeakBED.append(pos)\n",
    "                        subpeakDict[gene].add(overlap)\n",
    "                    \n",
    "    print(f'# of subpeaks: {len(subpeakBED)}')\n",
    "    '''\n",
    "    subpeakBED_uniq_set = set()\n",
    "    subpeakBED_uniq = []\n",
    "    for line in subpeakBED:\n",
    "        pos = f'{line[0]}:{line[1]}-{line[2]}'\n",
    "        if pos not in subpeakBED_uniq_set:\n",
    "            subpeakBED_uniq.append(line)\n",
    "            subpeakBED_uniq_set.add(pos)\n",
    "    \n",
    "    print(f'# of uniq subpeaks: {len(subpeakBED_uniq)}')\n",
    "    '''\n",
    "    \n",
    "    if motifExtension != 0:\n",
    "        bedfilename = projectFolder + projectName + '_subpeaks_ext500.bed'\n",
    "    else:\n",
    "        bedfilename = projectFolder + projectName + '_subpeaks_ext0.bed'\n",
    "\n",
    "                    \n",
    "    \n",
    "    # make fasta file\n",
    "    # fasta = []\n",
    "    \n",
    "    # for gene in subpeakDict:\n",
    "        # for subpeak in subpeakDict[gene]:\n",
    "            \n",
    "            # fastaTitle = gene + '|'  + subpeak.chr() + '|' + str(subpeak.start()) + '|' + str(subpeak.end())\n",
    "            # fastaLine = fetchSeq(genomeDirectory, subpeak.chr(), int(subpeak.start()+1), int(subpeak.end()+1))\n",
    "            \n",
    "            # fasta.append('>' + fastaTitle)\n",
    "            # fasta.append(fastaLine.upper())\n",
    "    \n",
    "    # outname = projectFolder + projectName + '_SUBPEAKS.fa'\n",
    "    # unParseTable(fasta, outname, '')\n",
    "    # print(f'writing subpeakDict to {outname}')\n",
    "     \n",
    "    unParseTable(subpeakBED, bedfilename, '\\t')\n",
    "    \n",
    "    return subpeakDict, subpeakBED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "64c9a62c-b004-4b96-a404-472eb8f87b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifExtension: 500\n",
      "MAKE FASTA\n",
      "549\n",
      "# of subpeaks: 7925\n",
      "write table to ./CRCmapper/1-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoffSE_ext500/CRUP_HI-32_K27ac_subpeaks_ext500.bed\n"
     ]
    }
   ],
   "source": [
    "# subpeakDict: TF_NMid: SE constituents\n",
    "print(f'motifExtension: {motifExtension}')\n",
    "subpeakDict, subpeakBED = generateSubpeakFASTA(newTFandTADdict, superLoci, subpeaks, genomeDirectory, projectName, projectFolder, motifExtension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43a3e658-8744-4314-bbc6-f10b7ce42a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifExtension: 0\n",
      "MAKE FASTA\n",
      "549\n",
      "# of subpeaks: 5223\n",
      "write table to ./CRCmapper/3-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext0/CRUP_HI-32_K27ac_subpeaks_ext0.bed\n"
     ]
    }
   ],
   "source": [
    "# subpeakDict: TF_NMid: SE constituents\n",
    "print(f'motifExtension: {motifExtension}')\n",
    "subpeakDict0, subpeakBED0 = generateSubpeakFASTA(newTFandTADdict, superLoci, subpeaks, genomeDirectory, projectName, projectFolder, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05407a9-dea5-428d-8ae6-b9578c357a85",
   "metadata": {},
   "source": [
    "## .5 TRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faefe6e3-0c77-4cc4-a2a4-e5a385d5a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d2fe2e-cd4b-4ef3-a794-5d3a7cdd36bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candidateGenes2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m r \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/gene\u001b[39m\u001b[38;5;124m'\u001b[39m, flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfindall(r, lines[i]):\n\u001b[0;32m---> 10\u001b[0m     r \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mcandidateGenes2\u001b[49m), flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mIGNORECASE)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfindall(r, lines[i]):\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# print(lines[i], end=\"\")\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         mat\u001b[38;5;241m.\u001b[39mwritelines(lines[i])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'candidateGenes2' is not defined"
     ]
    }
   ],
   "source": [
    "# create TRAP matrix: candidateMotifs.fa\n",
    "with open('/project/ngsvin/bin/TRAP/Data/merged_matrices.TFP_2022.2.fa', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # mat = open('/project/NeuralNet/CRC/CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500/Beta_canidateMotifs.fa', 'w')\n",
    "    mat = open(projectFolder+projectName+'_canidateMotifs.fa', 'w')\n",
    "    for i in range(0, len(lines)): # len(lines)\n",
    "        if lines[i].startswith('>V'):\n",
    "            r = re.compile('/gene', flags=re.IGNORECASE)\n",
    "            if re.findall(r, lines[i]):\n",
    "                r = re.compile('|'.join(candidateGenes2), flags=re.IGNORECASE)\n",
    "                if re.findall(r, lines[i]):\n",
    "                    # print(lines[i], end=\"\")\n",
    "                    mat.writelines(lines[i])\n",
    "                    j = i+1\n",
    "                    while not lines[j].startswith('>'):\n",
    "                        # print(lines[j], end=\"\")\n",
    "                        mat.writelines(lines[j])\n",
    "                        j += 1\n",
    "                        if j >= len(lines):\n",
    "                            break;\n",
    "    mat.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1265f2d-61ed-4926-a306-b730dbcca346",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project/ngsvin/bin/TRAP/Data/merged_matrices.TFP_2022.2.fa', 'r') as f:\n",
    "    motif2TFdict = {}\n",
    "    lines = f.readlines()\n",
    "    for i in range(0, len(lines)): # len(lines)\n",
    "        if lines[i].startswith('>V'):\n",
    "            r = re.compile('/gene', flags=re.IGNORECASE)\n",
    "            if re.findall(r, lines[i]):\n",
    "                line = lines[i].replace('\\n', '').split(' /')\n",
    "                r = re.compile('name')\n",
    "                name = list(filter(r.match, line))[0].split('=')[1]\n",
    "                r = re.compile('gene')\n",
    "                gene = list(filter(r.match, line))[0].split('=')[1]\n",
    "                if gene not in motif2TFdict.keys():\n",
    "                    motif2TFdict[gene] = []\n",
    "                    motif2TFdict[gene].append(name)\n",
    "                else:\n",
    "                    motif2TFdict[gene].append(name)\n",
    "# 1490 TF with 7353 motifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "id": "5b36b196-62dc-4ecf-a7ec-d6f2ddf63c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "print(len(subpeakDict.keys()))  # number of candidate TF 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "id": "b9abf20e-1000-49c2-ba3d-6b863e4a4d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFX8\n",
      "PREB\n",
      "EAF2\n",
      "TOX3\n",
      "MYT1\n",
      "TUB\n",
      "ARID1B\n",
      "BATF2\n",
      "UBTF\n",
      "SIM1\n",
      "WHSC1\n",
      "MYT1L\n",
      "HOPX\n",
      "ZBTB25\n",
      "MXD1\n",
      "CAMTA2\n",
      "GRHL3\n",
      "CREBL2\n",
      "ID3\n",
      "ZBTB8A\n",
      "CIC\n",
      "ADNP\n",
      "NPAS4\n",
      "TSC22D1\n",
      "HHEX\n",
      "ZKSCAN2\n",
      "PGR\n",
      "ID1\n",
      "RERE\n",
      "ZNF589\n",
      "TSHZ1\n",
      "HES4\n",
      "RCOR2\n",
      "ARID1A\n",
      "WIZ\n",
      "IKZF4\n",
      "# of total motifs: 1812\n",
      "# of TF that has motifs: 272\n"
     ]
    }
   ],
   "source": [
    "# for checking the number of motifs\n",
    "count = 0\n",
    "TFcount = 0\n",
    "for i in candidateGenes2:\n",
    "    if i in motif2TFdict.keys():\n",
    "        count += len(motif2TFdict[i])\n",
    "        TFcount += 1\n",
    "    else:\n",
    "        print(i)\n",
    "print(f'# of total motifs: {count}')\n",
    "print(f'# of TF that has motifs: {TFcount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1f3111-67af-430e-98dd-3c65e305dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run TRAP on shell\n",
    "TRAP='/project/ngsvin/bin/TRAP/TRAPv1.04'\n",
    "genome='/project/NeuralNet/CRC/ChIP-seq/mapping/bowtie2/hg19/hg19.fa'\n",
    "norm='/project/ngsvin/bin/TRAP/Data/hg19.TSSup.TFP_2022.2.GEVparams'\n",
    "folder='/project/NeuralNet/CRC/CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500/Beta_'\n",
    "matrix=${folder}'canidateMotifs.fa'\n",
    "region=${folder}'subpeaks_ext500.bed'\n",
    "$TRAP -thread 20 -s $genome -norm $norm -matrix $matrix -region $region -gene > ${folder}TRAPresults_ext500.bed &\n",
    "$TRAP -thread 10 -s $genome -norm $norm -matrix $matrix -region $region -gene -w 5000 > ${folder}TRAPresults_ext500_win5k.bed &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37159988-2491-425a-8040-6ace08f1e162",
   "metadata": {},
   "source": [
    "## .6 findAuto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31e6bbe4-8e3c-41c8-a8ef-e8aca0d09f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil, log\n",
    "import networkx as nx\n",
    "from networkx.algorithms.clique import find_cliques_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24d1461b-0502-4cb1-bad3-de0b88bd937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posTF(subpeakDict):\n",
    "    posTFdict = {}\n",
    "    for TF in subpeakDict.keys():\n",
    "        for peak in subpeakDict[TF]:\n",
    "            peakPos = f'{peak.chr()}:{peak.start()}-{peak.end()}'\n",
    "            if peakPos in posTFdict.keys():\n",
    "                # print(peakPos)\n",
    "                posTFdict[peakPos].append(TF)\n",
    "            else:\n",
    "                posTFdict[peakPos] = [TF]\n",
    "\n",
    "    print(len(posTFdict.keys()))\n",
    "    print(dict(list(posTFdict.items())[0:5]))\n",
    "    \n",
    "    return posTFdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55ad8465-3323-4a8e-97ab-acd88f658224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5223\n",
      "{'chr17:2787000-2789200': ['MNT'], 'chr17:3721700-3722800': ['MNT'], 'chr17:2340800-2343000': ['MNT', 'HIC1'], 'chr17:2356200-2357300': ['MNT', 'HIC1'], 'chr17:1882600-1883700': ['MNT', 'HIC1']}\n"
     ]
    }
   ],
   "source": [
    "#posTFdict = posTF(subpeakDict)\n",
    "posTFdict = posTF(subpeakDict0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f159e29-fc55-474d-ab2a-7c842079a9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MNT': 'MNT', 'HIC1': 'MNT,HIC1', 'ZNF664': 'ZNF664', 'SREBF1': 'SREBF1', 'CDC5L': 'CDC5L'}\n"
     ]
    }
   ],
   "source": [
    "# {gene: other genes in the same TAD}\n",
    "ggDict = {}\n",
    "for genes in posTFdict.values():\n",
    "    for gene in genes:\n",
    "        if gene not in ggDict.keys():\n",
    "            ggDict[gene] = ','.join(genes)\n",
    "print(dict(list(ggDict.items())[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "id": "556e3680-0a6c-4383-af3f-5a9210ee57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAPfile = './CRCmapper/1-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoffSE_ext0/' + projectName + '_TRAPresults_ext' + str(0) + '.bed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "94c97151-0e67-482f-ba02-3b3f4b942fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak_chr</th>\n",
       "      <th>peak_start</th>\n",
       "      <th>peak_end</th>\n",
       "      <th>motif</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>204052701</td>\n",
       "      <td>204053800</td>\n",
       "      <td>V$AFP1_Q6#ZFHX3</td>\n",
       "      <td>0.536265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>204052701</td>\n",
       "      <td>204053800</td>\n",
       "      <td>V$AP4_01#TFAP4</td>\n",
       "      <td>0.353191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>204052701</td>\n",
       "      <td>204053800</td>\n",
       "      <td>V$AP4_Q5#TFAP4</td>\n",
       "      <td>0.191597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>204052701</td>\n",
       "      <td>204053800</td>\n",
       "      <td>V$AP4_Q6#TFAP4</td>\n",
       "      <td>0.127290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>204052701</td>\n",
       "      <td>204053800</td>\n",
       "      <td>V$AP4_Q6_01#TFAP4</td>\n",
       "      <td>0.114891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  peak_chr  peak_start   peak_end              motif   p_value\n",
       "0     chr1   204052701  204053800    V$AFP1_Q6#ZFHX3  0.536265\n",
       "1     chr1   204052701  204053800     V$AP4_01#TFAP4  0.353191\n",
       "2     chr1   204052701  204053800     V$AP4_Q5#TFAP4  0.191597\n",
       "3     chr1   204052701  204053800     V$AP4_Q6#TFAP4  0.127290\n",
       "4     chr1   204052701  204053800  V$AP4_Q6_01#TFAP4  0.114891"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAPfile = projectFolder + projectName + '_TRAPresults_ext' + str(motifExtension) + '.bed'\n",
    "TRAPdf = pd.read_table(TRAPfile, skiprows=1, header=None, sep='\\t', names=['peak_chr', 'peak_start', 'peak_end', 'motif', 'p_value'])\n",
    "TRAPdf = TRAPdf.astype({'peak_start': int, 'peak_end': int, 'p_value': float})\n",
    "TRAPdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "66ca1e50-dd39-40bc-af4c-2aad25838639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak</th>\n",
       "      <th>peak_gene</th>\n",
       "      <th>motif_name</th>\n",
       "      <th>motif_gene</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1:204052700-204053800</td>\n",
       "      <td>SOX13</td>\n",
       "      <td>V$AFP1_Q6</td>\n",
       "      <td>ZFHX3</td>\n",
       "      <td>0.536265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1:204052700-204053800</td>\n",
       "      <td>SOX13</td>\n",
       "      <td>V$AP4_01</td>\n",
       "      <td>TFAP4</td>\n",
       "      <td>0.353191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1:204052700-204053800</td>\n",
       "      <td>SOX13</td>\n",
       "      <td>V$AP4_Q5</td>\n",
       "      <td>TFAP4</td>\n",
       "      <td>0.191597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1:204052700-204053800</td>\n",
       "      <td>SOX13</td>\n",
       "      <td>V$AP4_Q6</td>\n",
       "      <td>TFAP4</td>\n",
       "      <td>0.127290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1:204052700-204053800</td>\n",
       "      <td>SOX13</td>\n",
       "      <td>V$AP4_Q6_01</td>\n",
       "      <td>TFAP4</td>\n",
       "      <td>0.114891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       peak peak_gene   motif_name motif_gene   p_value\n",
       "0  chr1:204052700-204053800     SOX13    V$AFP1_Q6      ZFHX3  0.536265\n",
       "1  chr1:204052700-204053800     SOX13     V$AP4_01      TFAP4  0.353191\n",
       "2  chr1:204052700-204053800     SOX13     V$AP4_Q5      TFAP4  0.191597\n",
       "3  chr1:204052700-204053800     SOX13     V$AP4_Q6      TFAP4  0.127290\n",
       "4  chr1:204052700-204053800     SOX13  V$AP4_Q6_01      TFAP4  0.114891"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAPdf['peak'] = TRAPdf[TRAPdf.columns[:3]].apply(lambda x: f'{x[0]}:{x[1]-1}-{x[2]}', axis=1)\n",
    "TRAPdf[['motif_name', 'motif_gene']] = TRAPdf.motif.str.split('#', expand=True)\n",
    "TRAPdf['peak_gene'] = TRAPdf.peak.apply(lambda x: ','.join(posTFdict[x]))\n",
    "TRAPdf = TRAPdf[['peak', 'peak_gene', 'motif_name', 'motif_gene', 'p_value']]\n",
    "TRAPdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "83d0355b-0b12-4126-8053-80b8fe3cf03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak</th>\n",
       "      <th>peak_gene</th>\n",
       "      <th>motif_name</th>\n",
       "      <th>motif_gene</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>chr4:85354900-85356000</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_02</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>chr4:85412800-85413900</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_01</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>chr4:85356400-85357500</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_02</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.003698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>chr4:85354900-85356000</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_08</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>chr4:85356400-85357500</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_07</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.004921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>chr4:85356400-85357500</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_03</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.005840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>chr4:85364100-85365200</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_03</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.010696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>chr4:85354900-85356000</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_07</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.011121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>chr4:85411600-85412700</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_09</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.013128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>chr4:85377800-85378900</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>V$NKX61_10</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.014696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       peak peak_gene  motif_name motif_gene   p_value\n",
       "27   chr4:85354900-85356000    NKX6-1  V$NKX61_02     NKX6-1  0.000103\n",
       "194  chr4:85412800-85413900    NKX6-1  V$NKX61_01     NKX6-1  0.003127\n",
       "225  chr4:85356400-85357500    NKX6-1  V$NKX61_02     NKX6-1  0.003698\n",
       "276  chr4:85354900-85356000    NKX6-1  V$NKX61_08     NKX6-1  0.004600\n",
       "293  chr4:85356400-85357500    NKX6-1  V$NKX61_07     NKX6-1  0.004921\n",
       "353  chr4:85356400-85357500    NKX6-1  V$NKX61_03     NKX6-1  0.005840\n",
       "603  chr4:85364100-85365200    NKX6-1  V$NKX61_03     NKX6-1  0.010696\n",
       "626  chr4:85354900-85356000    NKX6-1  V$NKX61_07     NKX6-1  0.011121\n",
       "728  chr4:85411600-85412700    NKX6-1  V$NKX61_09     NKX6-1  0.013128\n",
       "794  chr4:85377800-85378900    NKX6-1  V$NKX61_10     NKX6-1  0.014696"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene = 'NKX6-1'\n",
    "TRAPdf[TRAPdf.motif_gene == gene].sort_values(by = 'p_value', ignore_index = True).query(\"peak_gene == @ggDict[@gene]\", engine='python').head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25144897-bfb8-4589-a881-086ac62c9aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36561, 5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAPdf[TRAPdf.motif_gene == gene].sort_values(by = 'p_value', ignore_index = True).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a381f756-12ac-4c54-8186-b7f244f1cc44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr4:85354900-85356000</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr4:85412800-85413900</td>\n",
       "      <td>0.003127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr4:85356400-85357500</td>\n",
       "      <td>0.003698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr4:85364100-85365200</td>\n",
       "      <td>0.010696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr4:85411600-85412700</td>\n",
       "      <td>0.013128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chr4:85377800-85378900</td>\n",
       "      <td>0.014696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chr4:85342100-85343200</td>\n",
       "      <td>0.021309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chr4:85353700-85354800</td>\n",
       "      <td>0.037722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chr4:84469200-84470300</td>\n",
       "      <td>0.038683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chr4:85338100-85339200</td>\n",
       "      <td>0.039896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chr4:85374900-85376000</td>\n",
       "      <td>0.053886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chr4:85399300-85400400</td>\n",
       "      <td>0.064541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chr4:85415100-85416200</td>\n",
       "      <td>0.071232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chr4:85406200-85407300</td>\n",
       "      <td>0.111082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chr4:85392200-85393300</td>\n",
       "      <td>0.112030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chr4:85245500-85246600</td>\n",
       "      <td>0.116269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chr4:85031000-85032100</td>\n",
       "      <td>0.138372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chr4:84455600-84456700</td>\n",
       "      <td>0.141435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chr4:85400600-85402800</td>\n",
       "      <td>0.142839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chr4:85340600-85341700</td>\n",
       "      <td>0.145273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chr4:85376500-85377600</td>\n",
       "      <td>0.213423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      peak   p_value\n",
       "0   chr4:85354900-85356000  0.000103\n",
       "1   chr4:85412800-85413900  0.003127\n",
       "2   chr4:85356400-85357500  0.003698\n",
       "3   chr4:85364100-85365200  0.010696\n",
       "4   chr4:85411600-85412700  0.013128\n",
       "5   chr4:85377800-85378900  0.014696\n",
       "6   chr4:85342100-85343200  0.021309\n",
       "7   chr4:85353700-85354800  0.037722\n",
       "8   chr4:84469200-84470300  0.038683\n",
       "9   chr4:85338100-85339200  0.039896\n",
       "10  chr4:85374900-85376000  0.053886\n",
       "11  chr4:85399300-85400400  0.064541\n",
       "12  chr4:85415100-85416200  0.071232\n",
       "13  chr4:85406200-85407300  0.111082\n",
       "14  chr4:85392200-85393300  0.112030\n",
       "15  chr4:85245500-85246600  0.116269\n",
       "16  chr4:85031000-85032100  0.138372\n",
       "17  chr4:84455600-84456700  0.141435\n",
       "18  chr4:85400600-85402800  0.142839\n",
       "19  chr4:85340600-85341700  0.145273\n",
       "20  chr4:85376500-85377600  0.213423"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene = 'NKX6-1'\n",
    "TRAPdf[TRAPdf.motif_gene == gene].sort_values(by = 'p_value', ignore_index = True).query(\"peak_gene == @ggDict[@gene]\", engine='python').groupby('peak')['p_value'].min().reset_index().sort_values(by = 'p_value', ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "id": "9d7c90f1-1f06-452a-8c37-fd49ba322c9c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOSL2,106968,17,0.00132844\n",
      "ELF1,280791,638,0.00716889\n",
      "NKX2-2,80226,484,0.00457029\n",
      "ZNF687,13371,639,0.0471801\n",
      "XBP1,120339,1147,0.00929125\n",
      "SCRT2,93597,848,0.0086011\n",
      "ZBTB11,40113,237,0.00518569\n",
      "ZNF785,13371,37,0.00134973\n",
      "FOXK1,147081,795,0.0053527\n",
      "ISL1,120339,48,0.00240391\n",
      "ZNF513,40113,50,0.000632387\n",
      "E2F2,120339,88,0.00107724\n",
      "ZBTB17,40113,16,0.00140586\n",
      "DBP,106968,1098,0.00736771\n",
      "KLF9,66855,527,0.0209501\n",
      "NR1D1,66855,52,0.000556938\n",
      "ETS1,187194,1098,0.0123001\n",
      "ZNF707,13371,67,0.0020391\n",
      "FOXP4,13371,102,0.00865321\n",
      "SP1,267420,940,0.0256598\n",
      "ZBTB7B,80226,66,0.002233\n",
      "ZNF182,40113,123,0.000987638\n",
      "STAT6,93597,519,0.00555898\n",
      "EGR4,93597,238,0.00503014\n",
      "ZNF668,26742,1355,0.0488445\n",
      "JUN,147081,737,0.00450663\n",
      "YY1,254049,1287,0.00667287\n",
      "TEF,160452,705,0.00322107\n",
      "ZNF526,26742,128,0.00827388\n",
      "NR2F6,133710,364,0.00165618\n",
      "KLF13,106968,130,0.00773248\n",
      "ZNF575,13371,7671,0.684752\n",
      "BHLHE40,160452,4436,0.027605\n",
      "ZFHX2,13371,188,0.0110161\n",
      "ZNF646,40113,136,0.00379208\n",
      "FOS,227307,2239,0.0071246\n",
      "EGR3,147081,64,0.00168975\n",
      "ARID3A,40113,118,0.0107651\n",
      "SOX12,53484,275,0.00398937\n",
      "USF2,160452,326,0.00557659\n",
      "ZNF641,13371,284,0.0194077\n",
      "ATF2,160452,3387,0.0231258\n",
      "STAT4,93597,66,0.00222772\n",
      "ZNF555,40113,1673,0.0491412\n",
      "FOSB,66855,338,0.00603107\n",
      "ZNF771,66855,53,0.000712524\n",
      "PPARA,66855,352,0.0045751\n",
      "ZNF410,66855,147,0.00061489\n",
      "ZNF652,66855,8,3.79604e-06\n",
      "GZF1,26742,521,0.0240492\n",
      "ARID5B,26742,27,0.000742433\n",
      "SALL4,93597,45,0.000535529\n",
      "ZNF696,26742,103,0.00344267\n",
      "STAT2,40113,68,0.000842186\n",
      "ESR2,93597,363,0.00228527\n",
      "ZSCAN20,40113,613,0.0127183\n",
      "RFX2,147081,130,0.00159884\n",
      "RARA,227307,131,0.000992184\n",
      "NFE2L2,106968,641,0.00242861\n",
      "CDC5L,13371,309,0.0257971\n",
      "SP2,160452,461,0.0153048\n",
      "MAX,200565,12,0.000163995\n",
      "ASCL2,120339,48,0.0015958\n",
      "ZNF576,13371,2004,0.24495\n",
      "ZBTB20,53484,48,0.00121733\n",
      "RFX5,147081,253,0.0021319\n",
      "ZNF57,40113,4857,0.122039\n",
      "ESRRA,254049,148,0.00154029\n",
      "RORA,80226,376,0.00387519\n",
      "ATOH7,26742,437,0.00683028\n",
      "HIVEP2,13371,1642,0.0498105\n",
      "FOXQ1,40113,25,0.00016941\n",
      "SOX9,200565,4,6.16789e-09\n",
      "STAT5B,80226,192,0.00465347\n",
      "ZBTB48,26742,1085,0.0469465\n",
      "NR2C2,160452,153,0.00192176\n",
      "ZNF572,40113,8,0.000665316\n",
      "HOMEZ,26742,137,0.00458812\n",
      "TEAD1,120339,340,0.00389969\n",
      "ZBTB44,40113,135,0.0117816\n",
      "ZBED1,66855,13,0.000518574\n",
      "RARG,173823,169,0.00142778\n",
      "FOXP2,40113,47,0.00154535\n",
      "RXRA,200565,1058,0.00586881\n",
      "TBX6,53484,580,0.00667052\n",
      "ZNF334,26742,57,0.00145633\n",
      "TFAP4,200565,1207,0.00610115\n",
      "ZBTB7A,147081,9,0.000167766\n",
      "ZNF76,80226,718,0.0126369\n",
      "MAZ,93597,58,0.00996801\n",
      "HOXB2,80226,69,0.000169432\n",
      "TEAD4,93597,129,0.00215925\n",
      "HLF,80226,84,0.00131852\n",
      "CEBPB,200565,686,0.00296418\n",
      "ZFHX3,13371,2605,0.172602\n",
      "ZNF23,66855,259,0.00552712\n",
      "FOXJ2,106968,12,5.6047e-06\n",
      "PBX1,187194,689,0.00512383\n",
      "HEY1,80226,577,0.0143076\n",
      "PRDM15,80226,90,0.00130531\n",
      "NFKB1,160452,4467,0.0268223\n",
      "TFEB,53484,328,0.0093737\n",
      "CREB3L2,40113,62,0.00171152\n",
      "MAFB,133710,185,0.000947342\n",
      "ZNF276,80226,112,0.0011123\n",
      "TCF7,160452,721,0.00278971\n",
      "NRF1,106968,1638,0.0552755\n",
      "ZNF74,26742,714,0.0204746\n",
      "ZNF623,26742,182,0.00399654\n",
      "ZNF629,53484,59,0.000402738\n",
      "FOXA3,120339,486,0.00185949\n",
      "KLF10,93597,165,0.0143813\n",
      "NR3C1,187194,1314,0.00548995\n",
      "ZNF48,40113,327,0.00853939\n",
      "NKX6-1,93597,72,0.000103196\n",
      "HNF1A,173823,44,7.10558e-06\n",
      "ZNF335,53484,341,0.00588679\n",
      "ZNF510,26742,302,0.00508803\n",
      "ZNF236,106968,257,0.00143343\n",
      "TFCP2,147081,2921,0.0222177\n",
      "NR1H3,53484,31,0.00110299\n",
      "DEAF1,26742,41,0.00327828\n",
      "RORC,93597,179,0.00200541\n",
      "ZNF300,53484,331,0.0051186\n",
      "IRF1,106968,1757,0.0120046\n",
      "ZBTB43,26742,557,0.0129527\n",
      "TEAD3,53484,1797,0.0317808\n",
      "THRA,53484,101,0.00279366\n",
      "CBFB,26742,13,0.00195529\n",
      "ZNF213,26742,95,0.00386339\n",
      "STAT5A,147081,89,0.00281803\n",
      "ZNF662,13371,71,0.00572145\n",
      "PLAGL2,80226,87,0.0014096\n",
      "ZNF484,40113,518,0.0110591\n",
      "MLXIP,13371,147,0.0396744\n",
      "ZNF133,53484,201,0.0017989\n",
      "JDP2,173823,2313,0.0079485\n",
      "PAX6,133710,67,0.000484688\n",
      "ZBTB34,13371,101,0.00389137\n",
      "RFX3,160452,641,0.00382963\n",
      "ZNF146,53484,999,0.0178477\n",
      "E2F6,53484,32906,0.890063\n",
      "SOX13,26742,13,0.000940942\n",
      "SIX2,106968,195,0.00111043\n",
      "SIX3,53484,1226,0.0300746\n",
      "GATA6,160452,369,0.00119503\n",
      "ZFP3,106968,64,0.000476191\n",
      "HES1,106968,234,0.00854983\n",
      "PPARD,53484,612,0.00910814\n",
      "FOXA2,173823,215,0.000757403\n",
      "CREB3,133710,304,0.00395868\n",
      "IRF3,133710,835,0.00644141\n",
      "GMEB2,80226,32,0.000820116\n",
      "TFDP1,26742,231,0.0260408\n",
      "MNT,26742,60,0.00909141\n",
      "TEAD2,80226,2100,0.0210364\n",
      "ZSCAN2,80226,252,0.00379644\n",
      "ZNF394,66855,189,0.0023572\n",
      "FOXM1,120339,101,0.00111331\n",
      "STAT3,120339,47,0.00229647\n",
      "MLX,66855,976,0.030303\n",
      "NFYA,93597,2150,0.0506091\n",
      "DDIT3,53484,379,0.00402873\n",
      "ZNF664,13371,28,0.00118654\n",
      "TRERF1,13371,2205,0.171773\n",
      "ZNF554,40113,4349,0.0945879\n",
      "NR4A1,160452,306,0.00410091\n",
      "PATZ1,53484,151,0.0209133\n",
      "ZFP64,93597,24,0.00019233\n",
      "CEBPE,80226,305,0.00529893\n",
      "EHF,133710,722,0.00888677\n",
      "ZBTB40,26742,215,0.00582697\n",
      "E2F4,160452,109,0.00280049\n",
      "SATB1,40113,52,0.00111461\n",
      "NR2C1,66855,770,0.019034\n",
      "E4F1,93597,406,0.00483864\n",
      "FOXO1,187194,217,0.00126244\n",
      "MAFA,120339,25,0.000285853\n",
      "STAT1,147081,9,0.000160145\n",
      "ZNF142,13371,110,0.0206327\n",
      "HINFP,93597,23,0.000819196\n",
      "MAFF,240678,532,0.000702703\n",
      "ZNF516,13371,176,0.0079914\n",
      "ZBTB4,40113,204,0.0030859\n",
      "MEIS1,106968,10,6.79177e-05\n",
      "MAFG,227307,3,1.3068e-06\n",
      "IRF9,66855,43,0.000327442\n",
      "INSM1,13371,31,0.00308917\n",
      "HSF4,53484,51,0.00241346\n",
      "GLIS2,66855,1398,0.0239664\n",
      "VEZF1,40113,377,0.0133984\n",
      "GLIS3,66855,378,0.0069\n",
      "ZNF77,53484,1528,0.0325676\n",
      "TFE3,133710,200,0.00437667\n",
      "BCLAF1,13371,114,0.0186188\n",
      "ZFP41,53484,351,0.00685372\n",
      "GRHL1,53484,269,0.0035786\n",
      "ZNF689,40113,339,0.00537707\n",
      "ATF5,13371,2341,0.150205\n",
      "TCF3,267420,1906,0.0111229\n",
      "HIC1,106968,96,0.00149027\n",
      "GLI1,106968,130,0.00115597\n",
      "NFATC2,106968,195,0.00286905\n",
      "ZNF22,26742,1219,0.00806948\n",
      "RXRG,106968,1343,0.00760328\n",
      "SREBF1,187194,57,0.00107459\n",
      "JUND,187194,83,0.00106999\n",
      "MAFK,173823,1675,0.00421336\n",
      "ZNF333,13371,3469,0.171901\n",
      "FOXO3,147081,826,0.00547445\n",
      "BHLHE41,80226,2841,0.0429851\n",
      "ZFP1,93597,109,0.000898909\n",
      "FOXK2,26742,771,0.0185454\n",
      "KLF16,66855,85,0.00680221\n",
      "ZNF500,13371,77,0.00619\n",
      "LCOR,13371,43,0.00338987\n",
      "OVOL2,80226,1252,0.0165074\n",
      "ZNF565,40113,4897,0.138122\n",
      "HES6,13371,35,0.00197103\n",
      "SRF,240678,3576,0.0109996\n",
      "NEUROD1,106968,95,0.00106299\n",
      "ARNT,66855,175,0.00758523\n",
      "NR4A2,120339,138,0.00143406\n",
      "ATF7,40113,359,0.0104968\n",
      "CREB3L4,80226,625,0.00924449\n",
      "ATF1,106968,22,0.000845385\n",
      "MEIS2,133710,11,0.00012697\n",
      "NFIC,106968,137,0.00240281\n",
      "PBX2,40113,329,0.00750699\n",
      "HNF4A,441243,502,0.00204697\n",
      "ZNF740,93597,437,0.00507528\n",
      "MEIS3,93597,592,0.00549813\n",
      "ZNF574,53484,307,0.0057962\n",
      "GMEB1,53484,29,0.00129723\n",
      "E2F1,213936,198,0.00682756\n",
      "RELB,13371,17,0.00567479\n",
      "SOX15,93597,356,0.00373937\n",
      "ZNF30,66855,147,0.00153098\n",
      "KLF11,53484,78,0.00677356\n",
      "TP53,160452,403,0.00156621\n",
      "REST,227307,1843,0.00731731\n",
      "NFE2L1,40113,49,0.000578388\n",
      "IRF7,93597,497,0.00456431\n",
      "ZNF205,26742,314,0.00688644\n",
      "ZNF408,26742,127,0.00329203\n",
      "ZBTB1,13371,499,0.045073\n",
      "HMBOX1,53484,103,0.00122654\n",
      "RFX1,160452,256,0.00265743\n",
      "ERF,40113,264,0.0176532\n",
      "ZNF319,26742,79,0.00272312\n",
      "RREB1,80226,1493,0.0191479\n",
      "ZNF296,53484,31,0.00185199\n",
      "PRDM10,26742,16,0.00060174\n",
      "NFYB,40113,305,0.0266072\n",
      "PDX1,240678,304,0.00101526\n",
      "ZNF341,53484,343,0.00933744\n",
      "ZBTB3,26742,170,0.00568175\n",
      "PROX1,40113,3328,0.0854467\n",
      "ZBTB47,13371,39,0.00359253\n",
      "SREBF2,106968,466,0.00427862\n",
      "ZNF175,66855,1865,0.023156\n",
      "ELK4,160452,728,0.0151886\n",
      "FOXJ1,40113,23,3.37051e-05\n",
      "RBAK,53484,9,3.8318e-05\n",
      "SNAPC4,26742,56,0.00114268\n",
      "MNX1,66855,390,0.007663\n",
      "HIF1A,106968,214,0.00751228\n",
      "ATF4,173823,1069,0.0051454\n",
      "EGR1,334275,925,0.0156308\n",
      "ZBTB24,66855,109,0.00184154\n",
      "ZNF79,26742,100,0.0018734\n",
      "ZFP62,66855,2130,0.0363071\n",
      "len(autoTF): 157\n",
      "len(edges): 32883, 32865\n"
     ]
    }
   ],
   "source": [
    "#percent = 0.001\n",
    "#percent = 0.0025\n",
    "percent = 0.005\n",
    "#percent = 0.01\n",
    "#percent = 0.02\n",
    "#percent = 0.04\n",
    "#percent = 0.05\n",
    "autoTF = set()\n",
    "pairDict = {}\n",
    "count = 0\n",
    "for TF in candidateGenes2:\n",
    "    TFdf = TRAPdf[TRAPdf.motif_gene == TF].sort_values(by='p_value', ignore_index=True)\n",
    "    listLen = TFdf.shape[0]\n",
    "    if listLen != 0:\n",
    "        cutoff = ceil(listLen * percent)\n",
    "        selfdf = TFdf.query(\"peak_gene == @ggDict[@TF]\", engine='python')\n",
    "        selfRank = selfdf.index[0]  + 1\n",
    "        selfP = selfdf['p_value'].values[0]\n",
    "        \n",
    "        i = 0\n",
    "        while selfP == 0.0:\n",
    "            selfP = selfdf['p_value'].values[i+1]\n",
    "            selfRank = selfdf.index[i+1] + 1\n",
    "            i += 1\n",
    "        print(TF, listLen, selfRank, selfP, sep=',')\n",
    "        \n",
    "        autoTF.add(TF)\n",
    "        pairdf = TFdf[:selfRank]\n",
    "        count += len(uniquify(pairdf.peak_gene))\n",
    "            \n",
    "        for i, TF2 in enumerate(pairdf.peak_gene):\n",
    "                if pairdf.p_value[i] == 0.0:\n",
    "                    continue;\n",
    "                if (TF, TF2) not in pairDict.keys():\n",
    "                    pairDict[(TF, TF2)] = pairdf.p_value[i]\n",
    "        \n",
    "        if (selfRank <= cutoff) and (selfP != 0.0):\n",
    "            autoTF.add(TF)\n",
    "            # print(TF, cutoff, selfRank, selfP, sep=',')\n",
    "            \n",
    "            pairdf = TFdf[:cutoff]\n",
    "            # count += len(uniquify(pairdf.peak_gene))\n",
    "            count += len(uniquify([TF for TFlist in pairdf.peak_gene.apply(lambda x: x.split(',')).values for TF in TFlist]))\n",
    "\n",
    "            \n",
    "            for i, TFls in enumerate(pairdf.peak_gene.apply(lambda x: x.split(',')).values):\n",
    "                if pairdf.p_value[i] == 0.0:\n",
    "                    # print((TF, TF2, pairdf.p_value[i]))\n",
    "                    continue;\n",
    "                for TF2 in TFls:\n",
    "                    if (TF, TF2) not in pairDict.keys():\n",
    "                        pairDict[(TF, TF2)] = pairdf.p_value[i]\n",
    "                    \n",
    "print(f'len(autoTF): {len(autoTF)}')\n",
    "print(f'len(edges): {count}, {len(pairDict.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "id": "08b76c55-d9f2-454c-8692-82edcedeb052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38440\n",
      "38440\n",
      "[('FOSL2', 'HNF4A', 9.546687616409244), ('FOSL2', 'ARID5B', 7.350229347971895), ('FOSL2', 'SOX9', 7.33873667630915), ('FOSL2', 'HES1', 7.183118869768971), ('FOSL2', 'NR3C1', 7.153416715571305), ('FOSL2', 'CEBPB', 6.961418748437814), ('FOSL2', 'MEIS3', 6.759404241759336), ('FOSL2', 'FOXK1', 6.7288646009276425), ('FOSL2', 'MAFK', 6.679504790299783), ('FOSL2', 'HIF1A', 6.675334890887718)]\n"
     ]
    }
   ],
   "source": [
    "edgeList = []\n",
    "for pair in pairDict.keys():\n",
    "    if (pair[0] in autoTF) and (pair[1] in autoTF):\n",
    "        edgeList.append((pair[0], pair[1], -log(pairDict[pair])))\n",
    "        #edgeList.append((pair[0], pair[1]))\n",
    "print(len(edgeList))\n",
    "print(len(set(edgeList)))\n",
    "print(edgeList[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13de309-fe4c-48c0-8f52-3875c3484182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()\n",
    "graph.add_nodes_from(autoTF)\n",
    "graph.add_weighted_edges_from(edgeList)\n",
    "\n",
    "autoRegNodeList = set()\n",
    "autoRegEdgeList = set()\n",
    "G = nx.DiGraph(name='Beta_narrow.05_broad.1_incltss_cutoff500_ext0_TRAP_noTAD')\n",
    "\n",
    "for n in autoTF:\n",
    "    for m in autoTF:\n",
    "        if n == m:\n",
    "            autoRegNodeList.add(n)\n",
    "            autoRegEdgeList.add((n, m, graph.edges[n, m]['weight']))\n",
    "        else:\n",
    "            if graph.has_edge(n,m) and graph.has_edge(m,n):\n",
    "                autoRegNodeList.add(n)\n",
    "                autoRegEdgeList.add((n, m, graph.edges[n, m]['weight']))\n",
    "                autoRegEdgeList.add((m, n, graph.edges[m, n]['weight']))\n",
    "                \n",
    "G.add_nodes_from(autoRegNodeList)\n",
    "G.add_weighted_edges_from(autoRegEdgeList)\n",
    "\n",
    "cliques = nx.find_cliques_recursive(G)\n",
    "cliqueList = list(cliques)\n",
    "\n",
    "cliqueRanking = []\n",
    "\n",
    "for clique in cliqueList:\n",
    "    cliqueScore = 0\n",
    "    edgeNum = 0\n",
    "    for n in clique:\n",
    "        for m in clique:\n",
    "            if n == m:\n",
    "                cliqueScore += G.edges[n, m]['weight']\n",
    "                edgeNum += 1\n",
    "            else:\n",
    "                cliqueScore += G.edges[n, m]['weight']\n",
    "                cliqueScore += G.edges[m, n]['weight']\n",
    "                edgeNum += 2\n",
    "                \n",
    "    cliqueRanking.append((clique, cliqueScore/edgeNum, len(clique)))\n",
    "    \n",
    "sortCliqueRanking = sorted(cliqueRanking, reverse=True, key=lambda x:x[1])\n",
    "sortCliqueRanking[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "id": "47feb59f-5b05-4bd2-bcde-35ecd121eeae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['MEIS2', 'ZBTB34', 'MNX1', 'NKX6-1', 'HOMEZ'], 7.883992341635171, 5),\n",
       " (['MEIS2', 'ZBTB34', 'MNX1', 'FOXP2'], 7.741351049477134, 4),\n",
       " (['MEIS2', 'FOXO1', 'ZNF276', 'HOMEZ', 'MNX1', 'NR3C1'],\n",
       "  7.438661155350288,\n",
       "  6),\n",
       " (['MEIS2', 'FOXO1', 'ZNF276', 'FOXP2', 'MNX1', 'MEIS1', 'NR3C1'],\n",
       "  7.338887034328841,\n",
       "  7),\n",
       " (['MEIS2', 'FOXO1', 'ELF1', 'HOMEZ', 'FOXK1', 'MNX1', 'NKX6-1', 'ZNF77'],\n",
       "  7.313715000754778,\n",
       "  8)]"
      ]
     },
     "execution_count": 1137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortCliqueRanking[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "id": "dcb2359a-943f-4c02-85f1-add867d59c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32214"
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = [[edge_data[0], edge_data[1], edge_data[-1][\"weight\"]] for edge_data in G.edges(data=True)]\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "id": "fd592add-8df8-4478-a0e1-80bb9cbe5771",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write table to ./CRCmapper/1-1-TAD-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoffSE_ext500/CRUP_HI-32_K27ac_CRC_SCORES_top1%_cross.txt\n"
     ]
    }
   ],
   "source": [
    "if percent >= 0.01:\n",
    "    autoTFFile = projectFolder + projectName + f'_AUTOREG_top{int(percent*100)}%.txt'\n",
    "    cliqueFile = projectFolder + projectName + f'_CRC_SCORES_top{int(percent*100)}%.txt'\n",
    "    edgeFile = projectFolder + projectName + f'_EDGES_top{int(percent*100)}%.txt'\n",
    "else:\n",
    "    autoTFFile = projectFolder + projectName + f'_AUTOREG_top{percent*100}%.txt'\n",
    "    cliqueFile = projectFolder + projectName + f'_CRC_SCORES_top{percent*100}%.txt'\n",
    "    edgeFile = projectFolder + projectName + f'_EDGES_top{percent*100}%.txt'\n",
    "\n",
    "unParseTable(sorted(autoTF), autoTFFile, '')\n",
    "unParseTable(sortCliqueRanking, cliqueFile, '\\t')\n",
    "unParseTable(edges, edgeFile, '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

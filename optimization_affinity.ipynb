{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d09741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary functions\n",
    "# cr: CRCmapper\n",
    "def parseTable(fn, sep, header = False,excel = False):\n",
    "    '''takes in a table where columns are separated by a given symbol and outputs\n",
    "    a nested list such that list[row][col]\n",
    "    example call:\n",
    "    table = parseTable('file.txt','\\t')\n",
    "    '''\n",
    "    fh = open(fn)\n",
    "    lines = fh.readlines()\n",
    "    fh.close()\n",
    "    if excel:\n",
    "        lines = lines[0].split('\\r')\n",
    "    if lines[0].count('\\r') > 0:\n",
    "        lines = lines[0].split('\\r')\n",
    "    table = []\n",
    "    if header == True:\n",
    "        lines =lines[1:]\n",
    "    for i in lines:\n",
    "        table.append(i[:-1].split(sep))\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def unParseTable(table, output, sep):\n",
    "    '''takes in a table generated by parseTable and writes it to an output file\n",
    "    takes as parameters (table, output, sep), where sep is how the file is delimited\n",
    "    example call unParseTable(table, 'table.txt', '\\t') for a tab del file\n",
    "    '''\n",
    "    fh_out = open(output,'w')\n",
    "    if len(sep) == 0:\n",
    "        for i in table:\n",
    "            fh_out.write(str(i))\n",
    "            fh_out.write('\\n')\n",
    "    else:\n",
    "        for line in table:\n",
    "            line = [str(x) for x in line]\n",
    "            line = sep.join(line)\n",
    "\n",
    "            fh_out.write(line)\n",
    "            fh_out.write('\\n')\n",
    "\n",
    "    fh_out.close()\n",
    "    \n",
    "\n",
    "'''uniquify function by Peter Bengtsson Used under a creative commons license\n",
    "sourced from  here: http://www.peterbe.com/plog/uniqifiers-benchmark\n",
    "'''\n",
    "def uniquify(seq, idfun=None):\n",
    "    if idfun is None:\n",
    "        def idfun(x): return x\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen: continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result\n",
    "\n",
    "\n",
    "def makeSearchLocus(locus,upSearch,downSearch):\n",
    "    '''takes a locus and expands it by a fixed upstream/downstream amount. spits out the new larger locus\n",
    "    '''\n",
    "    if locus.sense() == '-':\n",
    "        searchLocus = Locus(locus.chr(),locus.start()-downSearch,locus.end()+upSearch,locus.sense(),locus.ID())\n",
    "    else:\n",
    "        searchLocus = Locus(locus.chr(),locus.start()-upSearch,locus.end()+downSearch,locus.sense(),locus.ID())\n",
    "    return searchLocus\n",
    "\n",
    "\n",
    "def importRefseq(refseqFile, returnMultiples = False):\n",
    "\n",
    "    '''\n",
    "    opens up a refseq file downloaded by UCSC\n",
    "    '''\n",
    "    refseqTable = parseTable(refseqFile,'\\t')\n",
    "    refseqDict = {}\n",
    "    ticker = 1\n",
    "    for line in refseqTable[1:]:\n",
    "        if refseqDict.__contains__(line[1]):\n",
    "            refseqDict[line[1]].append(ticker)\n",
    "        else:\n",
    "            refseqDict[line[1]] = [ticker]\n",
    "        ticker = ticker + 1\n",
    "\n",
    "    multiples = []\n",
    "    for i in refseqDict:\n",
    "        if len(refseqDict[i]) > 1:\n",
    "            multiples.append(i)\n",
    "\n",
    "    if returnMultiples == True:\n",
    "        return refseqTable,refseqDict,multiples\n",
    "    else:\n",
    "        return refseqTable,refseqDict\n",
    "\n",
    "    \n",
    "def getTSSs(geneList,refseqTable,refseqDict):\n",
    "    if len(geneList) == 0:\n",
    "        refseq = refseqTable\n",
    "    else:\n",
    "        refseq = refseqFromKey(geneList,refseqDict,refseqTable)\n",
    "    TSS = []\n",
    "    for line in refseq:\n",
    "        if line[3] == '+':\n",
    "            TSS.append(line[4])\n",
    "        if line[3] == '-':\n",
    "            TSS.append(line[5])\n",
    "    TSS = map(int,TSS)\n",
    "    return TSS\n",
    "\n",
    "\n",
    "def refseqFromKey(refseqKeyList,refseqDict,refseqTable):\n",
    "    typeRefseq = []\n",
    "    for name in refseqKeyList:\n",
    "        if refseqDict.__contains__(name):\n",
    "            typeRefseq.append(refseqTable[refseqDict[name][0]])\n",
    "    return typeRefseq\n",
    "\n",
    "\n",
    "def makeStartDict(annotFile,geneList = []):\n",
    "    '''makes a dictionary keyed by refseq ID that contains information about \n",
    "    chrom/start/stop/strand/common name\n",
    "    '''\n",
    "\n",
    "    if type(geneList) == str:\n",
    "        geneList = parseTable(geneList,'\\t')\n",
    "        geneList = [line[0] for line in geneList]\n",
    "            \n",
    "    if annotFile.upper().count('REFSEQ') == 1:\n",
    "        refseqTable,refseqDict = importRefseq(annotFile)\n",
    "        if len(geneList) == 0:\n",
    "            geneList = refseqDict.keys()\n",
    "        startDict = {}\n",
    "        for gene in geneList:\n",
    "            if refseqDict.__contains__(gene) == False:\n",
    "                continue\n",
    "            startDict[gene]={}\n",
    "            startDict[gene]['sense'] = refseqTable[refseqDict[gene][0]][3]\n",
    "            startDict[gene]['chr'] = refseqTable[refseqDict[gene][0]][2]\n",
    "            startDict[gene]['start'] = [*getTSSs([gene],refseqTable,refseqDict)]\n",
    "            if startDict[gene]['sense'] == '+':\n",
    "                startDict[gene]['end'] =[int(refseqTable[refseqDict[gene][0]][5])]\n",
    "            else:\n",
    "                startDict[gene]['end'] = [int(refseqTable[refseqDict[gene][0]][4])]\n",
    "            startDict[gene]['name'] = refseqTable[refseqDict[gene][0]][12]\n",
    "    return startDict\n",
    "\n",
    "\n",
    "def makeTSSLocus(gene,startDict,upstream,downstream):\n",
    "    '''given a startDict, make a locus for any gene's TSS w/ upstream and downstream windows\n",
    "    '''\n",
    "    \n",
    "    start = startDict[gene]['start'][0]\n",
    "    if startDict[gene]['sense'] =='-':\n",
    "        return Locus(startDict[gene]['chr'],start-downstream,start+upstream,'-',gene)\n",
    "    else:\n",
    "        return Locus(startDict[gene]['chr'],start-upstream,start+downstream,'+',gene)\n",
    "    \n",
    "    \n",
    "def fetchSeq(directory,chrom,start,end,UCSC=False,lineBreaks=True,header = True):\n",
    "    '''function that fetches a sequence from a genome directory\n",
    "    directory that contains individual chrom fasta files\n",
    "    '''\n",
    "    fn = directory + chrom + '.fa'\n",
    "    fh = open(fn,'r')\n",
    "    headerOffset = 0\n",
    "    nStart = 0\n",
    "    nEnd = 0\n",
    "    if header:\n",
    "        fh.seek(0)\n",
    "        headerOffset = len(fh.readline())\n",
    "    if lineBreaks:\n",
    "\n",
    "        nStart = int((start-1)/50)\n",
    "        nEnd = int((end-1)/50)\n",
    "    if UCSC:\n",
    "        fh.seek((start+nStart+headerOffset))\n",
    "    else:\n",
    "        fh.seek((start-1+nStart+headerOffset))\n",
    "    span = ((end+nEnd-1)-(start+nStart-1))\n",
    "\n",
    "    read = fh.read(span)\n",
    "    if lineBreaks:\n",
    "        read = read.replace('\\n','')\n",
    "\n",
    "    return read\n",
    "    fh.close()\n",
    "\n",
    "    \n",
    "class Locus:\n",
    "    __chrDict = dict()\n",
    "    __senseDict = {'+':'+', '-':'-', '.':'.'}\n",
    "    def __init__(self,chr,start,end,sense,ID='',score=0):\n",
    "        coords = [int(start),int(end)]\n",
    "        # coords = [start, end]\n",
    "        coords.sort(reverse=False)\n",
    "        if not(self.__chrDict.__contains__(chr)): self.__chrDict[chr] = chr\n",
    "        self._chr = self.__chrDict[chr]\n",
    "        self._sense = self.__senseDict[sense]\n",
    "        self._start = int(coords[0])\n",
    "        self._end = int(coords[1])\n",
    "        self._ID = ID\n",
    "        self._score = score\n",
    "    def ID(self): return self._ID\n",
    "    def chr(self): return self._chr\n",
    "    def start(self): return self._start\n",
    "    def end(self): return self._end\n",
    "    def len(self): return self._end - self._start + 1\n",
    "    def score(self): return self._score\n",
    "    def getAntisenseLocus(self):\n",
    "        if self._sense=='.': return self\n",
    "        else:\n",
    "            switch = {'+':'-', '-':'+'}\n",
    "            return Locus(self._chr,self._start,self._end,switch[self._sense])\n",
    "    def coords(self): return [self._start,self._end]\n",
    "    def sense(self): return self._sense\n",
    "    def overlaps(self,otherLocus):\n",
    "        if self.chr()!=otherLocus.chr(): return False\n",
    "        elif not(self._sense=='.' or \\\n",
    "                 otherLocus.sense()=='.' or \\\n",
    "                 self.sense()==otherLocus.sense()): return False\n",
    "        elif self.start() > otherLocus.end() or otherLocus.start() > self.end(): return False\n",
    "        else: return True\n",
    "    def contains(self,otherLocus):\n",
    "        if self.chr()!=otherLocus.chr(): return False\n",
    "        elif not(self._sense=='.' or \\\n",
    "                 otherLocus.sense()=='.' or \\\n",
    "                 self.sense()==otherLocus.sense()): return False\n",
    "        elif self.start() > otherLocus.start() or otherLocus.end() > self.end(): return False\n",
    "        else: return True\n",
    "    def overlapsAntisense(self,otherLocus):\n",
    "        return self.getAntisenseLocus().overlaps(otherLocus)\n",
    "    def containsAntisense(self,otherLocus):\n",
    "        return self.getAntisenseLocus().contains(otherLocus)\n",
    "    def __hash__(self): return self._start + self._end\n",
    "    def __eq__(self,other):\n",
    "        if self.__class__ != other.__class__: return False\n",
    "        if self.chr()!=other.chr(): return False\n",
    "        if self.start()!=other.start(): return False\n",
    "        if self.end()!=other.end(): return False\n",
    "        if self.sense()!=other.sense(): return False\n",
    "        return True\n",
    "    def __ne__(self,other): return not(self.__eq__(other))\n",
    "    def __str__(self): return self.chr()+'('+self.sense()+'):'+'-'.join(map(str,self.coords()))\n",
    "    def plotStr(self): return self.chr() + ':' + self.sense() + ':' + '-'.join(map(str,self.coords()))\n",
    "    def checkRep(self):\n",
    "        pass\n",
    "    def gffLine(self): return [self.chr(),self.ID(),'',self.start(),self.end(),'',self.sense(),'',self.ID()]\n",
    "    \n",
    "    \n",
    "class LocusCollection:\n",
    "    def __init__(self,loci,windowSize):\n",
    "        self.__chrToCoordToLoci = dict()\n",
    "        self.__loci = dict()\n",
    "        self.__winSize = windowSize\n",
    "        for lcs in loci: self.__addLocus(lcs)\n",
    "\n",
    "    def __addLocus(self,lcs):\n",
    "        if not(self.__loci.__contains__(lcs)):\n",
    "            self.__loci[lcs] = None\n",
    "            if lcs.sense()=='.': chrKeyList = [lcs.chr()+'+', lcs.chr()+'-']\n",
    "            else: chrKeyList = [lcs.chr()+lcs.sense()]\n",
    "            for chrKey in chrKeyList:\n",
    "                if not(self.__chrToCoordToLoci.__contains__(chrKey)): self.__chrToCoordToLoci[chrKey] = dict()\n",
    "                for n in self.__getKeyRange(lcs):\n",
    "                    if not(self.__chrToCoordToLoci[chrKey].__contains__(n)): self.__chrToCoordToLoci[chrKey][n] = []\n",
    "                    self.__chrToCoordToLoci[chrKey][n].append(lcs)\n",
    "    def __getKeyRange(self,locus):\n",
    "        start = int(locus.start() / self.__winSize)\n",
    "        end = int(locus.end() / self.__winSize) + 1\n",
    "        return range(start,end)\n",
    "    def __len__(self): return len(self.__loci)\n",
    "        \n",
    "    def append(self,new): self.__addLocus(new)\n",
    "    def extend(self,newList):\n",
    "        for lcs in newList: self.__addLocus(lcs)\n",
    "    def hasLocus(self,locus):\n",
    "        return self.__loci.__contains__(locus)\n",
    "    def remove(self,old):\n",
    "        if not(self.__loci.__contains__(old)): raise ValueError(\"requested locus isn't in collection\")\n",
    "        del self.__loci[old]\n",
    "        if old.sense()=='.': senseList = ['+','-']\n",
    "        else: senseList = [old.sense()]\n",
    "        for k in self.__getKeyRange(old):\n",
    "            for sense in senseList:\n",
    "                self.__chrToCoordToLoci[old.chr()+sense][k].remove(old)\n",
    "    def getWindowSize(self): return self.__winSize\n",
    "    def getLoci(self): return self.__loci.keys()\n",
    "    def getChrList(self):\n",
    "        tempKeys = dict()\n",
    "        for k in self.__chrToCoordToLoci.keys(): tempKeys[k[:-1]] = None\n",
    "        return tempKeys.keys()\n",
    "            \n",
    "    def __subsetHelper(self,locus,sense):\n",
    "        sense = sense.lower()\n",
    "        if ['sense','antisense','both'].count(sense)!=1:\n",
    "            raise ValueError(\"sense command invalid: '\"+sense+\"'.\")\n",
    "        matches = dict()\n",
    "        senses = ['+','-']\n",
    "        if locus.sense()=='.' or sense=='both': lamb = lambda s: True\n",
    "        elif sense=='sense': lamb = lambda s: s==locus.sense()\n",
    "        elif sense=='antisense': lamb = lambda s: s!=locus.sense()\n",
    "        else: raise ValueError(\"sense value was inappropriate: '\"+sense+\"'.\")\n",
    "        for s in filter(lamb, senses):\n",
    "            chrKey = locus.chr()+s\n",
    "            if self.__chrToCoordToLoci.__contains__(chrKey):\n",
    "                for n in self.__getKeyRange(locus):\n",
    "                    if self.__chrToCoordToLoci[chrKey].__contains__(n):\n",
    "                        for lcs in self.__chrToCoordToLoci[chrKey][n]:\n",
    "                            matches[lcs] = None\n",
    "        return matches.keys()\n",
    "    def getOverlap(self,locus,sense='sense'):\n",
    "        matches = self.__subsetHelper(locus,sense)\n",
    "        realMatches = dict()\n",
    "        if sense=='sense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.overlaps(locus), matches):\n",
    "                realMatches[i] = None\n",
    "        if sense=='antisense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.overlapsAntisense(locus), matches):\n",
    "                realMatches[i] = None \n",
    "        return realMatches.keys()\n",
    "    def getContained(self,locus,sense='sense'):\n",
    "        matches = self.__subsetHelper(locus,sense)\n",
    "        realMatches = dict()\n",
    "        if sense=='sense' or sense=='both':\n",
    "            for i in filter(lambda lcs: locus.contains(lcs), matches):\n",
    "                realMatches[i] = None\n",
    "        if sense=='antisense' or sense=='both':\n",
    "            for i in filter(lambda lcs: locus.containsAntisense(lcs), matches):\n",
    "                realMatches[i] = None\n",
    "        return realMatches.keys()\n",
    "    def getContainers(self,locus,sense='sense'):\n",
    "        matches = self.__subsetHelper(locus,sense)\n",
    "        realMatches = dict()\n",
    "        if sense=='sense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.contains(locus), matches):\n",
    "                realMatches[i] = None\n",
    "        if sense=='antisense' or sense=='both':\n",
    "            for i in filter(lambda lcs: lcs.containsAntisense(locus), matches):\n",
    "                realMatches[i] = None\n",
    "        return realMatches.keys()\n",
    "    def stitchCollection(self,stitchWindow=1,sense='both'):\n",
    "        locusList = self.getLoci()\n",
    "        oldCollection = LocusCollection(locusList,500)\n",
    "        stitchedCollection = LocusCollection([],500)\n",
    "        for locus in locusList:\n",
    "            if oldCollection.hasLocus(locus):\n",
    "                oldCollection.remove(locus)\n",
    "                overlappingLoci = oldCollection.getOverlap(Locus(locus.chr(),locus.start()-stitchWindow,locus.end()+stitchWindow,locus.sense(),locus.ID()),sense)\n",
    "                stitchTicker = 1\n",
    "                while len(overlappingLoci) > 0:\n",
    "                    stitchTicker+=len(overlappingLoci)\n",
    "                    overlapCoords = locus.coords()\n",
    "                    for overlappingLocus in overlappingLoci:\n",
    "                        overlapCoords+=overlappingLocus.coords()\n",
    "                        oldCollection.remove(overlappingLocus)\n",
    "                    if sense == 'both':\n",
    "                        locus = Locus(locus.chr(),min(overlapCoords),max(overlapCoords),'.',locus.ID())\n",
    "                    else:\n",
    "                        locus = Locus(locus.chr(),min(overlapCoords),max(overlapCoords),locus.sense(),locus.ID())\n",
    "                    overlappingLoci = oldCollection.getOverlap(Locus(locus.chr(),locus.start()-stitchWindow,locus.end()+stitchWindow,locus.sense()),sense)\n",
    "                locus._ID = '%s_%s_lociStitched' % (stitchTicker,locus.ID())\n",
    "                stitchedCollection.append(locus)\n",
    "            else:\n",
    "                continue\n",
    "        return stitchedCollection\n",
    "    def getLoci(self): return self.__loci.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fbf665",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "import networkx as nx\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daac6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input files\n",
    "## for refseqToNameDict\n",
    "annotationFile = './CRCmapper/CRCmapper_package/annotation/hg19_refseq_NM.ucsc'\n",
    "annotTable = parseTable(annotationFile, '\\t')\n",
    "\n",
    "## refseqToNameDict\n",
    "refseqToNameDict = {}\n",
    "for line in annotTable[1:]:\n",
    "    gid = line[1]\n",
    "    genename = line[12].upper()\n",
    "    refseqToNameDict[gid] = genename\n",
    "# print(dict(list(refseqToNameDict.items())[0:5]))\n",
    "\n",
    "## SuperTable\n",
    "superFile = './ROSE/2.rose_Beta_narrow.05_broad.1_incltss/Beta_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "\n",
    "## SuperTable changed to tadTable\n",
    "# tadFile = './hg19.GSE63525_GM12878_50K.TopDom_10.bed'\n",
    "# tadTable = parseTable(tadFile, '\\t')\n",
    "# for i in range(1, len(tadTable)+1):\n",
    "#     tadTable[i-1].append(f'hg19_TAD_{i}')\n",
    "### chr start end type name \n",
    "## 3139\n",
    "\n",
    "## enhancerNumber\n",
    "## enhancerNumber = 500\n",
    "\n",
    "## expressionTable\n",
    "#expressionFile = './CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500/matrix.gff'\n",
    "# expressionFile = './CRCmapper/1-1.crc_HI-32_K27ac_incltss/matrix.gff'\n",
    "#expressionTable = parseTable(expressionFile, '\\t')\n",
    "\n",
    "## TFfile\n",
    "TFfile = './CRCmapper/CRCmapper_package/TFlist_NMid_hg.txt'\n",
    "TFtable = parseTable(TFfile, '\\t')\n",
    "TFlist = [line[0] for line in TFtable]\n",
    "TFlistGene = [line[1] for line in TFtable]\n",
    "\n",
    "## subpeaks\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_Beta_narrow.05_broad.1/Beta_peaks.broadPeak'\n",
    "# subpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\n",
    "\n",
    "## genomeDirectory FASTA (DNA sequences)\n",
    "genomeDirectory = './CRCmapper/hg19/'\n",
    "\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "\n",
    "## expCutoff: top 2/3 of the genes are considered to be expressed\n",
    "## expCutoff = 33\n",
    "\n",
    "## Transfac.v$ZIC2_01 ZIC2\n",
    "motifConvertFile = './CRCmapper/CRCmapper_package/MotifDictionary.txt'\n",
    "# motifDatabase = parseTable(motifConvertFile, '\\t')\n",
    "\n",
    "## PWM (motifDatabaseFile)\n",
    "PWMfile = './CRCmapper/CRCmapper_package/VertebratePWMs.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c5f11ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# 3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext0\\n## enhancerNumber\\nEnumber = 'SE'  # 668\\n## motifExtension\\nmotifExtension = 0\\n## working directory\\nprojectFolder = f'./CRCmapper/3-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/'\\nprojectName = 'CRUP_HI-32_K27ac'\\n## SuperTable\\nsuperFile = './ROSE/3-1.rose_CRUP_HI-32_K27ac_incltss_peakCutoff.8/islets_AllEnhancers.table.txt'\\nsuperTable = parseTable(superFile, '\\t')\\n## subpeak\\nsubpeaks = './crup/islets.HI-32.CRUP.singleEnh_peakCutoff.8.bed'\\n## expressionTable\\nexpressedNMfile = f'./CRCmapper/3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\\n\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# 2-2. Beta_narrow.05_broad.1_incltss_cutoff500_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 500\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'Beta'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2.rose_Beta_narrow.05_broad.1_incltss/Beta_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_Beta_narrow.05_broad.1/Beta_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext{motifExtension}/Beta_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "#'''\n",
    "# 2-2. Beta_narrow.05_broad.1_incltss_cutoff500_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 500\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'Beta'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2.rose_Beta_narrow.05_broad.1_incltss/Beta_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_Beta_narrow.05_broad.1/Beta_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff{Enumber}_ext500/Beta_EXPRESSED_TRANSCRIPTS.txt'\n",
    "#'''\n",
    "\n",
    "\n",
    "'''# 1-1. CRUP_HI-32_K27ac_incltss_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/1-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/1-1.rose_CRUP_HI-32_K27ac_incltss/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/1-1.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 1-1. CRUP_HI-32_K27ac_incltss_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/1-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/1-1.rose_CRUP_HI-32_K27ac_incltss/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/1-1.crc_CRUP_HI-32_K27ac_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 2-1. macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-1-TRAP.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'macs2_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2-1.rose_macs2_HI-32_K27ac_narrow.05_broad.05_incltss/H3K27ac_HI-32_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_HI-32_K27ac_narrow.05_broad.05/H3K27ac_HI-32_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-1.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 2-1. macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/2-1-TRAP.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'macs2_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/2-1.rose_macs2_HI-32_K27ac_narrow.05_broad.05_incltss/H3K27ac_HI-32_peaks_AllEnhancers.table.txt'\n",
    "# superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_HI-32_K27ac_narrow.05_broad.05/H3K27ac_HI-32_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/2-1.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoff{Enumber}_ext0/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 6-1.crc_DE_narrow.05_broad.05_exclNMtss_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/6-1-TRAP.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'DE'\n",
    "## SuperTable\n",
    "superFile = './ROSE/6.rose_DE_narrow.05_broad.05_exclNMtss/DE_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_DE_narrow.05_broad.05/DE_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/6-1.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext{motifExtension}/DE_H3K27ac_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 6-1.crc_DE_narrow.05_broad.05_exclNMtss_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/6-1-TRAP.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'DE'\n",
    "## SuperTable\n",
    "superFile = './ROSE/6.rose_DE_narrow.05_broad.05_exclNMtss/DE_peaks_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './ChIP-seq/Meissner/macs2_DE_narrow.05_broad.05/DE_peaks.broadPeak'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/6-1.crc_DE_narrow.05_broad.05_exclNMtss_cutoff{Enumber}_ext500/DE_H3K27ac_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext500\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'  # 668\n",
    "## motifExtension\n",
    "motifExtension = 500\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/3-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/3-1.rose_CRUP_HI-32_K27ac_incltss_peakCutoff.8/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh_peakCutoff.8.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext500/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''\n",
    "\n",
    "'''\n",
    "# 3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext0\n",
    "## enhancerNumber\n",
    "Enumber = 'SE'  # 668\n",
    "## motifExtension\n",
    "motifExtension = 0\n",
    "## working directory\n",
    "projectFolder = f'./CRCmapper/3-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/'\n",
    "projectName = 'CRUP_HI-32_K27ac'\n",
    "## SuperTable\n",
    "superFile = './ROSE/3-1.rose_CRUP_HI-32_K27ac_incltss_peakCutoff.8/islets_AllEnhancers.table.txt'\n",
    "superTable = parseTable(superFile, '\\t')\n",
    "## subpeak\n",
    "subpeaks = './crup/islets.HI-32.CRUP.singleEnh_peakCutoff.8.bed'\n",
    "## expressionTable\n",
    "expressedNMfile = f'./CRCmapper/3-1.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoff{Enumber}_ext{motifExtension}/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef26a9",
   "metadata": {},
   "source": [
    "## 1. createSuperLoci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9c90b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createSuperLoci(superTable, Enumber='SE'):\n",
    "    '''\n",
    "    takes as input a ROSE SuperEnhancer table \n",
    "    output a table of loci for SuperEnhancers\n",
    "    '''\n",
    "    \n",
    "    print('CREATING SUPER-ENHANCER LOCUS COLLECTION')\n",
    "    \n",
    "    output = []\n",
    "\n",
    "    if Enumber == 'SE':\n",
    "        for line in superTable[6:]:\n",
    "            if line[-1] == '1':\n",
    "                locus = Locus(line[1], line[2], line[3], '.', line[0], (float(line[6])-float(line[7])))\n",
    "                output.append(locus)\n",
    "    else:\n",
    "        end = 6+int(Enumber)\n",
    "        for line in superTable[6:end]:\n",
    "            locus = Locus(line[1], line[2], line[3], '.', line[0], (float(line[6])-float(line[7])))\n",
    "            output.append(locus)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "81f2bd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING SUPER-ENHANCER LOCUS COLLECTION\n",
      "chr16(.):46386031-46435529 chr1(.):121458818-121485538 chr9_gl000199_random(.):30876-169007 chr4(.):49093615-49157018 chr10(.):42355279-42409601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# superLoci = createSuperLoci(superTable, 500)\n",
    "superLoci = createSuperLoci(superTable, Enumber)\n",
    "print(*superLoci[:5])\n",
    "len(superLoci)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9f6e38",
   "metadata": {},
   "source": [
    "## 2. createExpressionDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "38f48589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14739\n",
      "./CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500/Beta_EXPRESSED_TRANSCRIPTS.txt\n"
     ]
    }
   ],
   "source": [
    "# expressedNM = createExpressionDict(annotationFile, projectFolder, projectName, refseqToNameDict, expressionTable)\n",
    "expressedNMfile = './CRCmapper/2-2.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500/Beta_EXPRESSED_TRANSCRIPTS.txt'\n",
    "# expressedNMfile = './CRCmapper/1-1.crc_CRUP_HI-32_K27ac_incltss_cutoffSE_ext500/H3K27ac_HI-32_EXPRESSED_TRANSCRIPTS.txt'\n",
    "with open(expressedNMfile, \"r\") as f:\n",
    "    expressedNM = [line.rstrip('\\n') for line in f]\n",
    "print(len(expressedNM))\n",
    "print(expressedNMfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388639d",
   "metadata": {},
   "source": [
    "## 3. findCanidateTFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b3ce4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCanidateTFs(annotationFile, superLoci, expressedNM, TFlist, refseqToNameDict, projectFolder, projectName):\n",
    "    '''\n",
    "    find all TFs within 1Mb of the super-enhancer center that are considered expressed \n",
    "    return a dictionary keyed by TF that points to a list of super-enhancer loci\n",
    "    '''\n",
    "\n",
    "    print('FINDING CANIDATE TFs')\n",
    "\n",
    "    startDict = makeStartDict(annotationFile)\n",
    "\n",
    "    # Find the location of the TSS of all transcripts (NMid) considered expressed\n",
    "    tssLoci = []\n",
    "    for geneID in expressedNM:\n",
    "        tssLoci.append(makeTSSLocus(geneID,startDict,0,0))\n",
    "    tssCollection = LocusCollection(tssLoci,50)\n",
    "\n",
    "    # Assign all transcripts (NMid) that are TFs to a super-enhancer if it is the closest gene\n",
    "    seAssignment = []\n",
    "    seAssignmentGene = []\n",
    "    TFandSuperDict = {}\n",
    "\n",
    "    for superEnh in superLoci:\n",
    "\n",
    "        seCenter = (superEnh.start() + superEnh.end()) / 2 \n",
    "\n",
    "        # Find all transcripts whose TSS occur within 1Mb of the SE center\n",
    "        searchLocus = Locus(superEnh.chr(), superEnh.start()-1000000, superEnh.end()+1000000, '.')\n",
    "        allEnhancerLoci = tssCollection.getOverlap(searchLocus)\n",
    "        allEnhancerGenes = [locus.ID() for locus in allEnhancerLoci]\n",
    "        #loc = [(locus.start(), locus.end()) for locus in allEnhancerLoci]\n",
    "\n",
    "        # Find the transcript that is closest to the center\n",
    "        if allEnhancerGenes:\n",
    "            distList = [abs(seCenter - startDict[geneID]['start'][0]) for geneID in allEnhancerGenes]\n",
    "            closestGene = allEnhancerGenes[distList.index(min(distList))]\n",
    "            #closestloc = loc[distList.index(min(distList))]\n",
    "        else:\n",
    "            closestGene = ''\n",
    "\n",
    "        seAssignment.append([superEnh.chr(), superEnh.start(), superEnh.end(), closestGene])\n",
    "\n",
    "        # Select the transcript if it is a TF, and allow for a TF to have multiple SEs\n",
    "        if closestGene in TFlist and closestGene not in TFandSuperDict.keys():\n",
    "            TFandSuperDict[closestGene] = [superEnh]\n",
    "        elif closestGene in TFlist and closestGene in TFandSuperDict.keys():\n",
    "            TFandSuperDict[closestGene].append(superEnh)\n",
    "\n",
    "        # Convert the selected TF NMids to gene names\n",
    "        if closestGene != '':\n",
    "            geneName = refseqToNameDict[closestGene]\n",
    "            seAssignmentGene.append([superEnh.chr(), superEnh.start(), superEnh.end(), geneName])\n",
    "            #seAssignmentGene.append([superEnh.chr(), superEnh.start(), superEnh.end(), geneName,\n",
    "                                     #closestloc[0], closestloc[1]])\n",
    "\n",
    "    #'''\n",
    "    # Output the list of SE-assigned transcripts (NMids)\n",
    "    seAssignmentFile = projectFolder + projectName + '_SE_ASSIGNMENT_TRANSCRIPT.txt'\n",
    "    #unParseTable(seAssignment, seAssignmentFile, '\\t')\n",
    "\n",
    "    # Output the list of SE-assigned genes\n",
    "    seAssignmentGeneFile = projectFolder + projectName + '_SE_ASSIGNMENT_GENE.txt'\n",
    "    #unParseTable(seAssignmentGene, seAssignmentGeneFile, '\\t')\n",
    "    #'''\n",
    "\n",
    "    print('Number of canidate TFs:', len(TFandSuperDict))\n",
    "\n",
    "    return TFandSuperDict#, seAssignmentGene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "74f11a5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINDING CANIDATE TFs\n",
      "Number of canidate TFs: 65\n"
     ]
    }
   ],
   "source": [
    "TFandSuperDict = findCanidateTFs(annotationFile, superLoci, expressedNM, TFlist, refseqToNameDict, projectFolder, projectName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "904bf473-574b-4d1a-8157-c14550cfaa6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINDING CANIDATE TFs\n",
      "Number of canidate TFs: 63\n"
     ]
    }
   ],
   "source": [
    "TFandSuperDict, seAssignmentGene = findCanidateTFs(annotationFile, superLoci, expressedNM, TFlist, refseqToNameDict, projectFolder, projectName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "1c3d8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatOutput(TFandSuperDict, refseqToNameDict, projectName, projectFolder):\n",
    "\n",
    "    '''\n",
    "    takes as input the dictionary mapping TFs to all proximal super-enhancers\n",
    "    returns a file that lists each candidate TFs\n",
    "    and gives the coordinates of the super-enhancers around them\n",
    "    '''\n",
    "\n",
    "    print('CREATE CANDIDATE TFs AND SE TABLE')\n",
    "\n",
    "    output = [['TF_refseq', 'TF_name', 'chr', 'start', 'stop', 'SuperID', 'Super_Load' ]]\n",
    "\n",
    "    used = []\n",
    " \n",
    "    for gene in TFandSuperDict.keys():\n",
    "        for superEnh in TFandSuperDict[gene]:\n",
    "\n",
    "            check = (refseqToNameDict[gene], superEnh.chr(), superEnh.start(), superEnh.end())\n",
    "\n",
    "            if check not in used:\n",
    "                newline = [gene, refseqToNameDict[gene]]\n",
    "                newline.append(superEnh.chr())\n",
    "                newline.append(superEnh.start())\n",
    "                newline.append(superEnh.end())\n",
    "                newline.append(superEnh.ID())\n",
    "                newline.append(superEnh.score())\n",
    "                output.append(newline)\n",
    "\n",
    "                used.append(check)\n",
    "\n",
    "    # Output the list of SE-assigned TFs and the associated super-enhancer loci\n",
    "    outputname = projectFolder + projectName + '_CANIDATE_TF_AND_SUPER_TABLE.txt'\n",
    "\n",
    "    unParseTable(output, outputname, '\\t')\n",
    "\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "4044ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE CANDIDATE TFs AND SE TABLE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatOutput(TFandSuperDict, refseqToNameDict, projectName, projectFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9c6663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateGenes = [refseqToNameDict[x].upper() for x in TFandSuperDict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "696c1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateGenes = uniquify(candidateGenes)\n",
    "len(candidateGenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765e6a8",
   "metadata": {},
   "source": [
    "## 4. TRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d96a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "dfeb093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TRAP matrix: candidateMotifs.fa\n",
    "with open('/project/ngsvin/bin/TRAP/Data/merged_matrices.TFP_2022.2.fa', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # mat = open('/project/NeuralNet/CRC/CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500/Beta_canidateMotifs.fa', 'w')\n",
    "    mat = open(projectFolder+projectName+'_canidateMotifs.fa', 'w')\n",
    "    for i in range(0, len(lines)): # len(lines)\n",
    "        if lines[i].startswith('>V'):\n",
    "            r = re.compile('/gene', flags=re.IGNORECASE)\n",
    "            if re.findall(r, lines[i]):\n",
    "                r = re.compile('|'.join(candidateGenes), flags=re.IGNORECASE)\n",
    "                if re.findall(r, lines[i]):\n",
    "                    # print(lines[i], end=\"\")\n",
    "                    mat.writelines(lines[i])\n",
    "                    j = i+1\n",
    "                    while not lines[j].startswith('>'):\n",
    "                        # print(lines[j], end=\"\")\n",
    "                        mat.writelines(lines[j])\n",
    "                        j += 1\n",
    "                        if j >= len(lines):\n",
    "                            break;\n",
    "    mat.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "612eb115",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/project/ngsvin/bin/TRAP/Data/merged_matrices.TFP_2022.2.fa', 'r') as f:\n",
    "    motif2TFdict = {}\n",
    "    lines = f.readlines()\n",
    "    for i in range(0, len(lines)): # len(lines)\n",
    "        if lines[i].startswith('>V'):\n",
    "            r = re.compile('/gene', flags=re.IGNORECASE)\n",
    "            if re.findall(r, lines[i]):\n",
    "                line = lines[i].replace('\\n', '').split(' /')\n",
    "                r = re.compile('name')\n",
    "                name = list(filter(r.match, line))[0].split('=')[1]\n",
    "                r = re.compile('gene')\n",
    "                gene = list(filter(r.match, line))[0].split('=')[1]\n",
    "                if gene not in motif2TFdict.keys():\n",
    "                    motif2TFdict[gene] = []\n",
    "                    motif2TFdict[gene].append(name)\n",
    "                else:\n",
    "                    motif2TFdict[gene].append(name)\n",
    "# 1490 TF with 7353 motifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "c8d2dd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIM1\n",
      "MYT1\n",
      "# of total motifs: 484\n",
      "# of TF that has motifs: 63\n"
     ]
    }
   ],
   "source": [
    "# for checking the number of motifs\n",
    "count = 0\n",
    "TFcount = 0\n",
    "for i in candidateGenes:\n",
    "    if i in motif2TFdict.keys():\n",
    "        count += len(motif2TFdict[i])\n",
    "        TFcount += 1\n",
    "    else:\n",
    "        print(i)\n",
    "print(f'# of total motifs: {count}')\n",
    "print(f'# of TF that has motifs: {TFcount}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473d837-2c76-459f-a846-994cd1988532",
   "metadata": {},
   "source": [
    "## 5. generateSubpeakFASTA\n",
    "TRAP_matrix + subpeaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3698b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateSubpeakFASTA(TFandSuperDict, subpeaks, genomeDirectory, projectName, projectFolder, motifExtension):\n",
    "    '''\n",
    "    takes as input a BED file of constituents\n",
    "    outputs a FASTA  file of merged extended super-enhancer consituents and associated formated name\n",
    "    '''\n",
    "\n",
    "    print('MAKE FASTA')\n",
    "\n",
    "    subpeakDict = {}\n",
    "    subpeakBED = []\n",
    "    subpeakTable = parseTable(subpeaks, '\\t')\n",
    "\n",
    "    subpeakLoci = [Locus(l[0], int(l[1]), int(l[2]), '.') for l in subpeakTable]\n",
    "    subpeakCollection = LocusCollection(subpeakLoci, 50)\n",
    "\n",
    "    for gene in TFandSuperDict.keys():\n",
    "        subpeakDict[gene] = []\n",
    "        for region in TFandSuperDict[gene]:\n",
    "            overlaps = subpeakCollection.getOverlap(region)\n",
    "            extendedOverlaps = [makeSearchLocus(x, motifExtension, motifExtension) for x in overlaps]\n",
    "\n",
    "            overlapCollectionTemp = LocusCollection(extendedOverlaps, 50)\n",
    "            overlapCollection = overlapCollectionTemp.stitchCollection()\n",
    "            for overlap in overlapCollection.getLoci():\n",
    "                subpeakBED.append([overlap.chr(), overlap.start(), overlap.end()])\n",
    "                subpeakDict[gene].append(overlap)\n",
    "\n",
    "    print(f'# of subpeaks: {len(subpeakBED)}')\n",
    "    if motifExtension != 0:\n",
    "        bedfilename = projectFolder + projectName + '_subpeaks_ext500.bed'\n",
    "    else:\n",
    "        bedfilename = projectFolder + projectName + '_subpeaks_ext0.bed'\n",
    "    \n",
    "\n",
    "    fasta = []\n",
    "\n",
    "    for gene in subpeakDict:\n",
    "        for subpeak in subpeakDict[gene]:\n",
    "\n",
    "            fastaTitle = gene + '|'  + subpeak.chr() + '|' + str(subpeak.start()) + '|' + str(subpeak.end())\n",
    "            fastaLine = fetchSeq(genomeDirectory, subpeak.chr(), int(subpeak.start()+1), int(subpeak.end()+1))\n",
    "\n",
    "            fasta.append('>' + fastaTitle)\n",
    "            fasta.append(fastaLine.upper())\n",
    "\n",
    "    # Output the fasta file of extended SE constituents\n",
    "    if motifExtension != 0:\n",
    "        outname = projectFolder + projectName + '_SUBPEAKS.fa'\n",
    "    else:\n",
    "        outname = projectFolder + projectName + '_SUBPEAKS_ext0.fa'\n",
    "\n",
    "    '''    \n",
    "    unParseTable(subpeakBED, bedfilename, '\\t')\n",
    "    unParseTable(fasta, outname, '')\n",
    "    '''\n",
    "    \n",
    "    return subpeakDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "f2099fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifExtension: 500\n",
      "MAKE FASTA\n",
      "# of subpeaks: 296\n"
     ]
    }
   ],
   "source": [
    "# subpeakDict: TF_NMid: SE constituents\n",
    "print(f'motifExtension: {motifExtension}')\n",
    "subpeakDict = generateSubpeakFASTA(TFandSuperDict, subpeaks, genomeDirectory, projectName, projectFolder, motifExtension)\n",
    "# subpeakDict = generateSubpeakFASTA(TFandSuperDict, subpeaks, genomeDirectory, projectName, projectFolder, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "985ba1fb-6586-4c29-8fce-0455fbaf11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motifExtension: 0\n",
      "MAKE FASTA\n",
      "# of subpeaks: 405\n"
     ]
    }
   ],
   "source": [
    "# subpeakDict: TF_NMid: SE constituents\n",
    "print(f'motifExtension: {motifExtension}')\n",
    "subpeakDict0 = generateSubpeakFASTA(TFandSuperDict, subpeaks, genomeDirectory, projectName, projectFolder, 0)\n",
    "# subpeakDict = generateSubpeakFASTA(TFandSuperDict, subpeaks, genomeDirectory, projectName, projectFolder, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7eb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run TRAP on shell\n",
    "TRAP='/project/ngsvin/bin/TRAP/TRAPv1.04'\n",
    "genome='/project/NeuralNet/CRC/ChIP-seq/mapping/bowtie2/hg19/hg19.fa'\n",
    "norm='/project/ngsvin/bin/TRAP/Data/hg19.TSSup.TFP_2022.2.GEVparams'\n",
    "folder='/project/NeuralNet/CRC/CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500/Beta_'\n",
    "matrix=${folder}'canidateMotifs.fa'\n",
    "region=${folder}'subpeaks_ext500.bed'\n",
    "$TRAP -thread 20 -s $genome -norm $norm -matrix $matrix -region $region -gene > ${folder}TRAPresults_ext500.bed &\n",
    "$TRAP -thread 10 -s $genome -norm $norm -matrix $matrix -region $region -gene -w 5000 > ${folder}TRAPresults_ext500_win5k.bed &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "1b4e7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subpeaks * motifs\n",
    "# # of peaks exceeded 5k in length / # of all peaks\n",
    "# (of # of TF that has motifs / # of unique candidate TF / # of candidate TF)\n",
    "# 2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext500: 2/296 peaks * 484 motifs (of 63/65/65 TF) = 143264 lines\n",
    "# 2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext0: 0/405 peaks * 484 motifs (of 63/65/65 TF) = 196020 lines\n",
    "# 1-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoffSE_ext500: 225/784 peaks * 653 motifs (of 83/94/97 TF) = 511952 lines\n",
    "# 1-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_cutoffSE_ext0: 2/1783 peaks * 653 motifs (of 83/94/97 TF) = 1164299 lines\n",
    "# 2-1-TRAP.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoffSE_ext0: 0/1069 peaks * 967 motifs (of 136/150/156 TF) = 1033723 lines\n",
    "# 2-1-TRAP.crc_macs2_HI-32_K27ac_narrow.05_broad.05_incltss_cutoffSE_ext500: 1/746 peaks * 967 motifs (of 136/150/156 TF) = 721382 lines\n",
    "# 6-1-TRAP.crc_DE_narrow.05_broad.05_excltss_cutoffSE_ext500: 25/188 peaks * 391 motifs (of 61/69/69 TF) = 73508 lines\n",
    "# 6-1-TRAP.crc_DE_narrow.05_broad.05_excltss_cutoffSE_ext0: 4/333 peaks * 391 motifs (of 61/69/69 TF) = 130203 lines\n",
    "# 3-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext500: 82/341 peaks * 411 motifs (of 55/62/63 TF) = 140151 lines\n",
    "# 3-1-TRAP.crc_CRUP_HI-32_K27ac_incltss_peakCutoff.8_cutoffSE_ext0: 0/691 peaks * 411 motifs (of 55/62/63 TF) = 284001 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d01cc3-900b-4d66-9dde-feb309ae430c",
   "metadata": {},
   "source": [
    "## 6. find autoTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "abe25a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import ceil, log\n",
    "import networkx as nx\n",
    "from networkx.algorithms.clique import find_cliques_recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eefa89f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posNMdict = {}\n",
    "for NM in subpeakDict0.keys():\n",
    "    TF = refseqToNameDict[NM]\n",
    "    for peak in subpeakDict0[NM]:\n",
    "        peakPos = f'{peak.chr()}:{peak.start()}-{peak.end()}'\n",
    "        if peakPos in posNMdict.keys():\n",
    "            print(peakPos)\n",
    "        posNMdict[peakPos] = TF\n",
    "dict(list(posNMdict.items())[0:5])\n",
    "len(posNMdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1df1e792-44f9-49b2-afa6-8bce0b75dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKey(dict, value):\n",
    "    return [k for k, v in dict.items() if value in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b7c09d43-f2ca-4d2a-95b2-6f99cf229c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NM_002196']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getKey(refseqToNameDict, 'INSM1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eaabac53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak_chr</th>\n",
       "      <th>peak_start</th>\n",
       "      <th>peak_end</th>\n",
       "      <th>motif</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>156459251</td>\n",
       "      <td>156459696</td>\n",
       "      <td>V$AFP1_Q6#ZFHX3</td>\n",
       "      <td>0.370081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>156459251</td>\n",
       "      <td>156459696</td>\n",
       "      <td>V$ARID3A_02#ARID3A</td>\n",
       "      <td>0.837649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>156459251</td>\n",
       "      <td>156459696</td>\n",
       "      <td>V$ARID3A_04#ARID3A</td>\n",
       "      <td>0.813306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>156459251</td>\n",
       "      <td>156459696</td>\n",
       "      <td>V$ATF4_02#ATF4</td>\n",
       "      <td>0.343902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>156459251</td>\n",
       "      <td>156459696</td>\n",
       "      <td>V$ATF4_03#ATF4</td>\n",
       "      <td>0.511825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  peak_chr  peak_start   peak_end               motif   p_value\n",
       "0     chr1   156459251  156459696     V$AFP1_Q6#ZFHX3  0.370081\n",
       "1     chr1   156459251  156459696  V$ARID3A_02#ARID3A  0.837649\n",
       "2     chr1   156459251  156459696  V$ARID3A_04#ARID3A  0.813306\n",
       "3     chr1   156459251  156459696      V$ATF4_02#ATF4  0.343902\n",
       "4     chr1   156459251  156459696      V$ATF4_03#ATF4  0.511825"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAPfile = projectFolder + projectName + '_TRAPresults_ext' + str(motifExtension) + '.bed'\n",
    "TRAPdf = pd.read_table(TRAPfile, skiprows=1, header=None, sep='\\t', names=['peak_chr', 'peak_start', 'peak_end', 'motif', 'p_value'])\n",
    "TRAPdf = TRAPdf.astype({'peak_start': int, 'peak_end': int, 'p_value': float})\n",
    "TRAPdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de62f98f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak</th>\n",
       "      <th>peak_gene</th>\n",
       "      <th>motif_name</th>\n",
       "      <th>motif_gene</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1:156459250-156459696</td>\n",
       "      <td>MEF2D</td>\n",
       "      <td>V$AFP1_Q6</td>\n",
       "      <td>ZFHX3</td>\n",
       "      <td>0.370081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1:156459250-156459696</td>\n",
       "      <td>MEF2D</td>\n",
       "      <td>V$ARID3A_02</td>\n",
       "      <td>ARID3A</td>\n",
       "      <td>0.837649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1:156459250-156459696</td>\n",
       "      <td>MEF2D</td>\n",
       "      <td>V$ARID3A_04</td>\n",
       "      <td>ARID3A</td>\n",
       "      <td>0.813306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1:156459250-156459696</td>\n",
       "      <td>MEF2D</td>\n",
       "      <td>V$ATF4_02</td>\n",
       "      <td>ATF4</td>\n",
       "      <td>0.343902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1:156459250-156459696</td>\n",
       "      <td>MEF2D</td>\n",
       "      <td>V$ATF4_03</td>\n",
       "      <td>ATF4</td>\n",
       "      <td>0.511825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       peak peak_gene   motif_name motif_gene   p_value\n",
       "0  chr1:156459250-156459696     MEF2D    V$AFP1_Q6      ZFHX3  0.370081\n",
       "1  chr1:156459250-156459696     MEF2D  V$ARID3A_02     ARID3A  0.837649\n",
       "2  chr1:156459250-156459696     MEF2D  V$ARID3A_04     ARID3A  0.813306\n",
       "3  chr1:156459250-156459696     MEF2D    V$ATF4_02       ATF4  0.343902\n",
       "4  chr1:156459250-156459696     MEF2D    V$ATF4_03       ATF4  0.511825"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAPdf['peak'] = TRAPdf[TRAPdf.columns[:3]].apply(lambda x: f'{x[0]}:{x[1]-1}-{x[2]}', axis=1)\n",
    "TRAPdf[['motif_name', 'motif_gene']] = TRAPdf.motif.str.split('#', expand=True)\n",
    "TRAPdf['peak_gene'] = TRAPdf.peak.apply(lambda x: posNMdict[x])\n",
    "TRAPdf = TRAPdf[['peak', 'peak_gene', 'motif_name', 'motif_gene', 'p_value']]\n",
    "TRAPdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1eb2f7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uniquify(TRAPdf.peak.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f523507c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak</th>\n",
       "      <th>peak_gene</th>\n",
       "      <th>motif_name</th>\n",
       "      <th>motif_gene</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121382</th>\n",
       "      <td>chr8:144522000-144523100</td>\n",
       "      <td>MAFA</td>\n",
       "      <td>V$PLAGL2_06</td>\n",
       "      <td>PLAGL2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244230</th>\n",
       "      <td>chr20:38648400-38649500</td>\n",
       "      <td>MAFB</td>\n",
       "      <td>V$NKX61_02</td>\n",
       "      <td>NKX6-1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            peak peak_gene   motif_name motif_gene  p_value\n",
       "121382  chr8:144522000-144523100      MAFA  V$PLAGL2_06     PLAGL2      0.0\n",
       "244230   chr20:38648400-38649500      MAFB   V$NKX61_02     NKX6-1      0.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAPdf.query(\"p_value == 0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f8fda8-00e1-404f-b522-0239a06b194c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak</th>\n",
       "      <th>peak_gene</th>\n",
       "      <th>motif_name</th>\n",
       "      <th>motif_gene</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>chr20:21504000-21505100</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>V$NKX2B_Q3</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>0.030906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>chr20:21487600-21489800</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>V$NKX2B_Q3_01</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>0.067742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>chr20:21516200-21517300</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>V$NKX22_06</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>0.070837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>chr20:21498700-21499800</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>V$NKX22_05</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>0.071840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>chr20:21487600-21489800</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>V$NKX22_02</td>\n",
       "      <td>NKX2-2</td>\n",
       "      <td>0.076473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        peak peak_gene     motif_name motif_gene   p_value\n",
       "150  chr20:21504000-21505100    NKX2-2     V$NKX2B_Q3     NKX2-2  0.030906\n",
       "342  chr20:21487600-21489800    NKX2-2  V$NKX2B_Q3_01     NKX2-2  0.067742\n",
       "357  chr20:21516200-21517300    NKX2-2     V$NKX22_06     NKX2-2  0.070837\n",
       "366  chr20:21498700-21499800    NKX2-2     V$NKX22_05     NKX2-2  0.071840\n",
       "395  chr20:21487600-21489800    NKX2-2     V$NKX22_02     NKX2-2  0.076473"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene = 'NKX2-2'\n",
    "TRAPdf[TRAPdf.motif_gene == gene].sort_values(by = 'p_value', ignore_index = True).query(\"peak_gene == @gene\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "e60e8b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFIC,5528,6,0.00240281\n",
      "PAX6,6910,24,0.00368251\n",
      "MEIS2,6910,52,0.00571461\n",
      "TEAD1,6219,13,0.0036393\n",
      "FOXP4,691,45,0.0296982\n",
      "MEF2D,4837,62,0.00825383\n",
      "SREBF1,9674,74,0.00911766\n",
      "MAFB,6910,86,0.0095147\n",
      "EHF,6910,40,0.00888677\n",
      "ZKSCAN1,5528,75,0.00885855\n",
      "NKX2-2,4146,151,0.0309056\n",
      "XBP1,6219,352,0.0671234\n",
      "JUNB,6910,192,0.0121691\n",
      "ISL1,6219,237,0.0440116\n",
      "MNT,1382,157,0.106692\n",
      "RREB1,4146,250,0.0543085\n",
      "FOXK1,7601,228,0.0244845\n",
      "FOXA2,8983,3,0.000757403\n",
      "PDX1,12438,13,0.00101526\n",
      "RARA,11747,239,0.0156828\n",
      "RFX2,7601,15,0.00238422\n",
      "MEIS1,5528,1,6.79177e-05\n",
      "ARID3A,2073,84,0.0649778\n",
      "RFX3,8292,29,0.00382963\n",
      "GLIS2,3455,93,0.0241344\n",
      "TFEB,2764,174,0.0625573\n",
      "ZBTB17,2073,243,0.158525\n",
      "JUND,9674,7,0.00106999\n",
      "CREB3L2,2073,47,0.0226889\n",
      "INSM1,691,203,0.275894\n",
      "MNX1,3455,38,0.00952651\n",
      "HSF4,2764,39,0.0103314\n",
      "BHLHE40,8292,256,0.0523247\n",
      "MLXIP,691,40,0.0564629\n",
      "PLAGL2,4146,41,0.00783373\n",
      "ZNF34,1382,3,0.00226769\n",
      "ARID5B,1382,77,0.0399475\n",
      "KLF9,3455,44,0.0262111\n",
      "SOX13,1382,58,0.02244\n",
      "RXRA,10365,129,0.00845888\n",
      "VEZF1,2073,95,0.0547808\n",
      "HES1,5528,6,0.00539544\n",
      "HLF,4146,451,0.0963634\n",
      "FOXP2,2073,24,0.00804036\n",
      "SATB1,2073,3,0.00111461\n",
      "ELF3,11056,878,0.0940516\n",
      "NKX6-1,4837,5,0.000103196\n",
      "PROX1,2073,184,0.0949301\n",
      "EGR4,4837,567,0.253007\n",
      "MAFA,6219,94,0.00849244\n",
      "SOX9,10365,17,0.0011503\n",
      "ZFHX3,691,164,0.197533\n",
      "ZBTB20,2764,214,0.0650454\n",
      "HNF1A,8983,57,0.00218511\n",
      "RORC,4837,80,0.0165754\n",
      "len(autoTF): 37\n",
      "len(edges): 1822\n"
     ]
    }
   ],
   "source": [
    "#percent = 0.01\n",
    "#percent = 0.02\n",
    "percent = 0.04\n",
    "#percent = 0.05\n",
    "autoTF = set()\n",
    "pairDict = {}\n",
    "count = 0\n",
    "for TF in candidateGenes:\n",
    "    TFdf = TRAPdf[TRAPdf.motif_gene == TF].sort_values(by='p_value', ignore_index=True)\n",
    "    listLen = TFdf.shape[0]\n",
    "    if listLen != 0:\n",
    "        cutoff = ceil(listLen * percent)\n",
    "        selfdf = TFdf.query(\"peak_gene == @TF\")\n",
    "        selfRank = selfdf.index[0]  + 1\n",
    "        selfP = selfdf['p_value'].values[0]\n",
    "        if (selfP == 0.0) and (selfdf.shape[0] > 1):\n",
    "            selfRank = selfdf.index[1] + 1\n",
    "            selfP = selfdf['p_value'].values[1]\n",
    "        print(TF, listLen, selfRank, selfP, sep=',')\n",
    "        \n",
    "        \n",
    "        if (selfRank <= cutoff) and (selfP != 0.0):\n",
    "            autoTF.add(TF)\n",
    "            # print(TF, cutoff, selfRank, selfP, sep=',')\n",
    "            \n",
    "            # pairdf = TFdf[:cutoff2]\n",
    "            pairdf = TFdf[:cutoff]\n",
    "            count += len(uniquify(pairdf.peak_gene))\n",
    "\n",
    "            \n",
    "            for i, TF2 in enumerate(pairdf.peak_gene):\n",
    "                if pairdf.p_value[i] == 0.0:\n",
    "                    # print((TF, TF2, pairdf.p_value[i]))\n",
    "                    continue;\n",
    "                if (TF, TF2) not in pairDict.keys():\n",
    "                    pairDict[(TF, TF2)] = pairdf.p_value[i]\n",
    "print(f'len(autoTF): {len(autoTF)}')\n",
    "print(f'len(edges): {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "4beedc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1822\n",
      "[('NFIC', 'RORC', 6.640480016308019), ('NFIC', 'RARA', 6.357301332839101), ('NFIC', 'RFX2', 6.1278296652285285), ('NFIC', 'SOX13', 6.1133610314059075), ('NFIC', 'JUND', 6.063828809638116), ('NFIC', 'NFIC', 6.031116393185708), ('NFIC', 'ZKSCAN1', 5.932659933443242), ('NFIC', 'MAFB', 5.917734646414269), ('NFIC', 'MEF2D', 5.808046924546965), ('NFIC', 'RXRA', 5.787929593914829)]\n"
     ]
    }
   ],
   "source": [
    "edgeList = []\n",
    "for pair in pairDict.keys():\n",
    "    edgeList.append((pair[0], pair[1], -log(pairDict[pair])))\n",
    "print(len(edgeList))\n",
    "print(edgeList[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "ea06f928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['EHF',\n",
       "   'PAX6',\n",
       "   'NKX6-1',\n",
       "   'FOXA2',\n",
       "   'PDX1',\n",
       "   'MAFB',\n",
       "   'RFX3',\n",
       "   'MEIS2',\n",
       "   'MEIS1',\n",
       "   'NKX2-2'],\n",
       "  5.7086623925828075,\n",
       "  10),\n",
       " (['EHF',\n",
       "   'PAX6',\n",
       "   'NKX6-1',\n",
       "   'FOXA2',\n",
       "   'PDX1',\n",
       "   'MAFB',\n",
       "   'ZKSCAN1',\n",
       "   'NKX2-2',\n",
       "   'JUND',\n",
       "   'MEIS2',\n",
       "   'MEIS1'],\n",
       "  5.707895075315044,\n",
       "  11),\n",
       " (['EHF',\n",
       "   'NFIC',\n",
       "   'NKX6-1',\n",
       "   'FOXA2',\n",
       "   'PDX1',\n",
       "   'MAFB',\n",
       "   'ZKSCAN1',\n",
       "   'NKX2-2',\n",
       "   'JUND',\n",
       "   'MEIS2',\n",
       "   'MEIS1'],\n",
       "  5.673364891786511,\n",
       "  11),\n",
       " (['EHF', 'NFIC', 'HNF1A', 'MAFB', 'FOXK1', 'CREB3L2', 'ZKSCAN1', 'NKX2-2'],\n",
       "  5.642290096236783,\n",
       "  8),\n",
       " (['EHF',\n",
       "   'PAX6',\n",
       "   'RARA',\n",
       "   'MAFB',\n",
       "   'MEIS1',\n",
       "   'MEIS2',\n",
       "   'ZKSCAN1',\n",
       "   'SOX9',\n",
       "   'NKX2-2',\n",
       "   'PDX1'],\n",
       "  5.63561196007308,\n",
       "  10)]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = nx.DiGraph()\n",
    "graph.add_nodes_from(autoTF)\n",
    "graph.add_weighted_edges_from(edgeList)\n",
    "\n",
    "autoRegNodeList = set()\n",
    "autoRegEdgeList = set()\n",
    "G = nx.DiGraph(name='Beta_narrow.05_broad.1_incltss_cutoff500_ext0_TRAP_noTAD')\n",
    "\n",
    "for n in autoTF:\n",
    "    for m in autoTF:\n",
    "        if n == m:\n",
    "            autoRegNodeList.add(n)\n",
    "            autoRegEdgeList.add((n, m, graph.edges[n, m]['weight']))\n",
    "        else:\n",
    "            if graph.has_edge(n,m) and graph.has_edge(m,n):\n",
    "                autoRegNodeList.add(n)\n",
    "                autoRegEdgeList.add((n, m, graph.edges[n, m]['weight']))\n",
    "                autoRegEdgeList.add((m, n, graph.edges[m, n]['weight']))\n",
    "                \n",
    "G.add_nodes_from(autoRegNodeList)\n",
    "G.add_weighted_edges_from(autoRegEdgeList)\n",
    "cliques = nx.find_cliques_recursive(G)\n",
    "cliqueList = list(cliques)\n",
    "\n",
    "cliqueRanking = []\n",
    "\n",
    "for clique in cliqueList:\n",
    "    cliqueScore = 0\n",
    "    edgeNum = 0\n",
    "    for n in clique:\n",
    "        for m in clique:\n",
    "            if n == m:\n",
    "                # continue;\n",
    "                cliqueScore += G.edges[n, m]['weight']\n",
    "                edgeNum += 1\n",
    "            else:\n",
    "                cliqueScore += G.edges[n, m]['weight']\n",
    "                cliqueScore += G.edges[m, n]['weight']\n",
    "                edgeNum += 2\n",
    "                \n",
    "    cliqueRanking.append((clique, cliqueScore/edgeNum, len(clique)))\n",
    "    \n",
    "sortCliqueRanking = sorted(cliqueRanking, reverse=True, key=lambda x:x[1])\n",
    "sortCliqueRanking[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "abcc5918-f439-49d3-abaa-67d8014caf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges = [[edge_data[0], edge_data[1], edge_data[-1][\"weight\"]] for edge_data in G.edges(data=True)]\n",
    "len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "f63e1e4a-9aa1-4fc9-a2e8-9db6987453ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "projectFolder = './CRCmapper/2-2-TRAP.crc_Beta_narrow.05_broad.1_incltss_cutoff500_ext0/'\n",
    "if percent >= 0.01:\n",
    "    autoTFFile = projectFolder + projectName + f'_AUTOREG_top{int(percent*100)}%.txt'\n",
    "    cliqueFile = projectFolder + projectName + f'_CRC_SCORES_top{int(percent*100)}%.txt'\n",
    "    edgeFile = projectFolder + projectName + f'_EDGES_top{int(percent*100)}%.txt'\n",
    "else:\n",
    "    autoTFFile = projectFolder + projectName + f'_AUTOREG_top{percent*100}%.txt'\n",
    "    cliqueFile = projectFolder + projectName + f'_CRC_SCORES_top{percent*100}%.txt'\n",
    "    edgeFile = projectFolder + projectName + f'_EDGES_top{percent*100}%.txt'\n",
    "\n",
    "unParseTable(sorted(autoTF), autoTFFile, '')\n",
    "unParseTable(sortCliqueRanking, cliqueFile, '\\t')\n",
    "unParseTable(edges, edgeFile, '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
